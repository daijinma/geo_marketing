import os
import logging
import yaml
import time
from dotenv import load_dotenv
import os
from core.parser import extract_domain
from core.db import get_db_connection, update_domain_stats
from providers.deepseek_web import DeepSeekWebProvider
from providers.doubao_web import DoubaoWebProvider

# æ ¹æ® ENV_FILE ç¯å¢ƒå˜é‡åŠ è½½ä¸åŒçš„ .env æ–‡ä»¶
env_file = os.getenv("ENV_FILE", ".env")
load_dotenv(env_file)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¹³å°åç§°æ˜ å°„ï¼ˆç”¨äºå‘åå…¼å®¹ï¼‰
platform_name_map = {}

def load_config():
    config_path = os.path.join(os.path.dirname(__file__), "config.yaml")
    if not os.path.exists(config_path):
        logger.error(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")
        return None
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def save_to_db(keyword, platform, prompt, result, prompt_type="default", response_time_ms=None, error_message=None):
    """ä¿å­˜æœç´¢ç»“æœåˆ°æ•°æ®åº“"""
    try:
        with get_db_connection() as conn:
            cur = conn.cursor()
            
            # ç¡®å®šæœç´¢çŠ¶æ€
            search_status = 'completed' if result and result.get("full_text") else 'failed'
            if error_message:
                search_status = 'failed'
            
            # 1. æ’å…¥æœç´¢è®°å½•
            cur.execute("""
                INSERT INTO search_records 
                (keyword, platform, prompt_type, prompt, full_answer, response_time_ms, search_status, error_message) 
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s) 
                RETURNING id
            """, (
                keyword, 
                platform, 
                prompt_type, 
                prompt,
                result.get("full_text", "") if result else "",
                response_time_ms,
                search_status,
                error_message
            ))
            record_id = cur.fetchone()[0]
            
            if not result:
                logger.warning(f"æœç´¢å¤±è´¥ï¼Œä»…ä¿å­˜äº†è®°å½• ID: {record_id}")
                return
            
            # 2. æ’å…¥æ‹“å±•è¯ (å¸¦é¡ºåº)
            for idx, query in enumerate(result.get("queries", []), 1):
                cur.execute(
                    "INSERT INTO search_queries (record_id, query, query_order) VALUES (%s, %s, %s)",
                    (record_id, query, idx)
                )
            
            # 3. æ’å…¥å¼•ç”¨ (åˆ©ç”¨å”¯ä¸€çº¦æŸè‡ªåŠ¨å»é‡)
            citations_count = 0
            for cite in result.get("citations", []):
                url = cite.get("url", "")
                if not url:
                    continue
                    
                domain = extract_domain(url)
                try:
                    cur.execute("""
                        INSERT INTO citations 
                        (record_id, cite_index, url, domain, title, snippet, site_name) 
                        VALUES (%s, %s, %s, %s, %s, %s, %s)
                        ON CONFLICT (record_id, url) DO NOTHING
                    """, (
                        record_id, 
                        cite.get("cite_index", 0), 
                        url, 
                        domain, 
                        cite.get("title", ""), 
                        cite.get("snippet", ""), 
                        cite.get("site_name", "")
                    ))
                    
                    if cur.rowcount > 0:
                        citations_count += 1
                        # æ›´æ–°åŸŸåç»Ÿè®¡
                        update_domain_stats(conn, domain, platform)
                        
                except Exception as e:
                    logger.debug(f"æ’å…¥å¼•ç”¨å¤±è´¥ï¼ˆå¯èƒ½é‡å¤ï¼‰: {e}")
            
            logger.info(f"âœ… æˆåŠŸä¿å­˜ {platform} çš„æ•°æ®ï¼Œè®°å½• ID: {record_id}")
            logger.info(f"  - æ‹“å±•è¯: {len(result.get('queries', []))} ä¸ª")
            logger.info(f"  - å‚è€ƒç½‘é¡µ: {citations_count} ä¸ª")
            if response_time_ms:
                logger.info(f"  - å“åº”æ—¶é—´: {response_time_ms/1000:.2f} ç§’")
                
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}", exc_info=True)

def run_tasks():
    config = load_config()
    if not config:
        return

    tasks = config.get("tasks", [])
    settings = config.get("settings", {})
    headless = settings.get("headless", False)
    timeout = settings.get("timeout", 60000)
    delay = settings.get("delay_between_tasks", 5)
    
    providers = {
        "deepseek": DeepSeekWebProvider(headless=headless, timeout=timeout),
        "doubao": DoubaoWebProvider(headless=headless, timeout=timeout)
    }
    
    
    platforms_to_run = os.getenv("PLATFORMS", "deepseek").split(",")
    
    for task in tasks:
        keyword = task.get("keyword")
        prompt = task.get("keyword") # task.get("prompt") or f"è¯·æœç´¢å¹¶è¯¦ç»†åˆ†æï¼š{keyword}ã€‚è¯·åˆ—å‡ºä½ å‚è€ƒçš„ä¸»è¦ç½‘ç«™æ¥æºã€‚"
        
        if not keyword:
            continue
            
        for name in platforms_to_run:
            original_name = name.strip()
            name = original_name
            
            # å°è¯•ç›´æ¥åŒ¹é…
            if name not in providers:
                # å°è¯•é€šè¿‡æ˜ å°„æŸ¥æ‰¾
                normalized_name = platform_name_map.get(name)
                if normalized_name and normalized_name in providers:
                    name = normalized_name
                else:
                    # å¤§å°å†™ä¸æ•æ„ŸåŒ¹é…
                    name_lower = name.lower()
                    matched = False
                    for key in providers.keys():
                        if key.lower() == name_lower:
                            name = key
                            matched = True
                            break
                    
                    if not matched:
                        logger.warning(f"æœªæ‰¾åˆ°å¹³å° [{original_name}] çš„ Provider")
                        logger.info(f"å¯ç”¨å¹³å°: {', '.join(providers.keys())}")
                        logger.info(f"æ”¯æŒçš„åˆ«å: {', '.join(platform_name_map.keys())}")
                        continue
                
            provider = providers[name]
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡: [{keyword}] åœ¨å¹³å° [{name}]")
            logger.info(f"{'='*60}")
            
            start_time = time.time()
            result = None
            error_message = None
            
            try:
                result = provider.search(keyword, prompt)
                response_time_ms = int((time.time() - start_time) * 1000)
                
                if result and result.get("full_text"):
                    save_to_db(keyword, name, prompt, result, prompt_type="config_task", response_time_ms=response_time_ms)
                    logger.info(f"âœ… {name} ä»»åŠ¡å®Œæˆ")
                else:
                    error_message = "æœªè¿”å›æœ‰æ•ˆç»“æœ"
                    logger.warning(f"âš ï¸ {name} {error_message}")
                    save_to_db(keyword, name, prompt, None, prompt_type="config_task", error_message=error_message)
                    
            except Exception as e:
                response_time_ms = int((time.time() - start_time) * 1000)
                error_message = str(e)
                logger.error(f"âŒ æ‰§è¡Œä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
                save_to_db(keyword, name, prompt, None, prompt_type="config_task", 
                          response_time_ms=response_time_ms, error_message=error_message)
            
            # ä»»åŠ¡é—´å»¶è¿Ÿ
            if delay > 0:
                logger.info(f"â³ ç­‰å¾… {delay} ç§’åæ‰§è¡Œä¸‹ä¸€ä¸ªä»»åŠ¡...\n")
                time.sleep(delay)
    
    logger.info("\n" + "="*60)
    logger.info("ğŸ‰ æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼")
    logger.info("="*60)

if __name__ == "__main__":
    import sys
    
    # æ”¯æŒé€šè¿‡å‘½ä»¤è¡Œå‚æ•°å¯åŠ¨ API æœåŠ¡å™¨
    if len(sys.argv) > 1 and sys.argv[1] == "api":
        import uvicorn
        port = int(os.getenv("API_PORT", "8000"))
        logger.info(f"å¯åŠ¨ API æœåŠ¡å™¨ï¼Œç«¯å£: {port}")
        uvicorn.run("api.app:app", host="0.0.0.0", port=port, reload=False)
    else:
        # é»˜è®¤è¡Œä¸ºï¼šè¿è¡Œé…ç½®æ–‡ä»¶ä¸­çš„ä»»åŠ¡
        run_tasks()
