import time
import os
import json
import re
from playwright.sync_api import sync_playwright
from providers.base import BaseProvider
from core.parser import extract_domain
from core.logger_config import setup_logger

class DeepSeekWebProvider(BaseProvider):
    def search(self, keyword: str, prompt: str):
        user_data_dir = os.path.join(os.getenv("BROWSER_DATA_DIR", "./browser_data"), "deepseek")
        
        # ç”¨äºŽå­˜å‚¨æ‹¦æˆªåˆ°çš„æœç´¢ç»“æžœ
        captured_search_results = []
        captured_queries = []  # å­˜å‚¨ AI æ‹“å±•çš„æœç´¢è¯
        full_response_text = ""
        
        def handle_response(response):
            """æ‹¦æˆª API å“åº”ï¼Œæå–æœç´¢ç»“æžœå’Œæ‹“å±•è¯"""
            nonlocal captured_search_results, captured_queries, full_response_text
            
            url_lower = response.url.lower()
            # æ‰©å±•APIç«¯ç‚¹åŒ¹é…æ¨¡å¼
            api_patterns = [
                "api/v0/chat/completion",
                "api/v1/chat/completion"
            ]
            self.logger.info(f"[ç½‘ç»œæ‹¦æˆª] å“åº”URL: {response.url}")
            if any(pattern in url_lower for pattern in api_patterns):
                matched_pattern = next((p for p in api_patterns if p in url_lower), "unknown")
                self.logger.info(f"[ç½‘ç»œæ‹¦æˆª] APIç«¯ç‚¹åŒ¹é…: {matched_pattern}")
                try:
                    content_type = response.headers.get("content-type", "")
                    
                    # å¤„ç† SSE æµ
                    if "text/event-stream" in content_type or "stream" in url_lower:
                        try:
                            body = response.text()
                            self.logger.info(f"[ç½‘ç»œæ‹¦æˆª] SSEæµå¼å“åº”ï¼Œå¼€å§‹è§£æžæ•°æ®")
                            
                            # æ­£ç¡®è§£æž SSE æ•°æ®æµ
                            # SSE æ ¼å¼ï¼šäº‹ä»¶ä¹‹é—´ç”¨ç©ºè¡Œåˆ†éš”ï¼Œä¸€ä¸ªäº‹ä»¶å¯ä»¥æœ‰å¤šè¡Œ data:
                            events = []
                            current_event_data = []
                            
                            for line in body.split('\n'):
                                line = line.rstrip('\r')  # ç§»é™¤å¯èƒ½çš„ \r
                                
                                if line.startswith('data: '):
                                    # æ”¶é›†å¤šè¡Œ data: å­—æ®µ
                                    data_content = line[6:]  # åŽ»æŽ‰ "data: " å‰ç¼€
                                    current_event_data.append(data_content)
                                elif line == '':
                                    # ç©ºè¡Œè¡¨ç¤ºäº‹ä»¶ç»“æŸï¼Œåˆå¹¶æ‰€æœ‰ data: è¡Œ
                                    if current_event_data:
                                        # å¤šè¡Œ data: åº”è¯¥ç”¨æ¢è¡Œç¬¦è¿žæŽ¥
                                        combined_data = '\n'.join(current_event_data)
                                        events.append(combined_data)
                                        current_event_data = []
                                elif line.startswith('event:') or line.startswith('id:') or line.startswith('retry:'):
                                    # å¿½ç•¥å…¶ä»– SSE å­—æ®µï¼ˆevent, id, retryï¼‰
                                    continue
                            
                            # å¤„ç†æœ€åŽä¸€ä¸ªäº‹ä»¶ï¼ˆå¦‚æžœæ²¡æœ‰ä»¥ç©ºè¡Œç»“å°¾ï¼‰
                            if current_event_data:
                                combined_data = '\n'.join(current_event_data)
                                events.append(combined_data)
                            
                            self.logger.debug(f"[SSEè§£æž] å…±è§£æžåˆ° {len(events)} ä¸ª SSE äº‹ä»¶")
                            
                            # å¤„ç†æ¯ä¸ªäº‹ä»¶çš„æ•°æ®
                            for event_data in events:
                                try:
                                    json_str = event_data.strip()
                                    if json_str and json_str != '[DONE]' and json_str != 'null':
                                        data = json.loads(json_str)
                                        
                                        # æå–æœç´¢ç»“æžœå’Œæ‹“å±•è¯
                                        if 'v' in data:
                                            # æƒ…å†µ1: å®Œæ•´çš„ fragments æ•°æ®
                                            if isinstance(data['v'], dict):
                                                response_data = data['v'].get('response', {})
                                                fragments = response_data.get('fragments', [])
                                                for frag in fragments:
                                                    if frag.get('type') == 'SEARCH':
                                                        # æå–æ‹“å±•è¯ (queries)
                                                        queries = frag.get('queries', [])
                                                        queries_before = len(captured_queries)
                                                        for q in queries:
                                                            if isinstance(q, dict):
                                                                query_text = q.get('query', q.get('text', ''))
                                                            else:
                                                                query_text = str(q)
                                                            if query_text and query_text not in captured_queries:
                                                                captured_queries.append(query_text)
                                                                self.logger.info(f"[æ•°æ®æŠ“å–] æŸ¥è¯¢è¯: {query_text}")
                                                        
                                                        if len(captured_queries) > queries_before:
                                                            self.logger.info(f"[æ•°æ®æŠ“å–] è¿›åº¦: {len(captured_queries)} ä¸ªæŸ¥è¯¢, {len(captured_search_results)} ä¸ªç½‘ç«™")
                                                        
                                                        # æå–æœç´¢ç»“æžœ (results)
                                                        results = frag.get('results', [])
                                                        results_before = len(captured_search_results)
                                                        for r in results:
                                                            if isinstance(r, dict) and r.get('url'):
                                                                url = r.get('url', '')
                                                                domain = extract_domain(url)
                                                                captured_search_results.append({
                                                                    "url": url,
                                                                    "title": r.get('title', r.get('name', '')),
                                                                    "snippet": r.get('snippet', r.get('description', '')),
                                                                    "site_name": r.get('site_name', r.get('source', '')),
                                                                    "cite_index": r.get('cite_index', r.get('index', 0)),
                                                                    "query_indexes": r.get('query_indexes', [])
                                                                })
                                                                self.logger.info(f"[æ•°æ®æŠ“å–] ç½‘ç«™: {url[:60]}... (åŸŸå: {domain})")
                                                        
                                                        if len(captured_search_results) > results_before:
                                                            self.logger.info(f"[æ•°æ®æŠ“å–] è¿›åº¦: {len(captured_queries)} ä¸ªæŸ¥è¯¢, {len(captured_search_results)} ä¸ªç½‘ç«™")
                                            
                                            # æƒ…å†µ2: å¢žé‡æ›´æ–°çš„ results æ•°ç»„ï¼ˆå…³é”®ä¿®å¤ï¼‰
                                            elif isinstance(data['v'], list):
                                                # æ£€æŸ¥è·¯å¾„å‚æ•°ï¼Œç¡®è®¤æ˜¯å¦æ˜¯ results æ›´æ–°
                                                path = data.get('p', '')
                                                
                                                # å¤„ç†å¢žé‡æ›´æ–°çš„ results: {"p":"response/fragments/-1/results","v":[...]}
                                                if 'results' in path.lower() or (len(data['v']) > 0 and isinstance(data['v'][0], dict) and 'url' in data['v'][0]):
                                                    results_before = len(captured_search_results)
                                                    for r in data['v']:
                                                        if isinstance(r, dict) and r.get('url'):
                                                            url = r.get('url', '')
                                                            domain = extract_domain(url)
                                                            captured_search_results.append({
                                                                "url": url,
                                                                "title": r.get('title', r.get('name', '')),
                                                                "snippet": r.get('snippet', r.get('description', '')),
                                                                "site_name": r.get('site_name', r.get('source', '')),
                                                                "cite_index": r.get('cite_index', r.get('index', 0)),
                                                                "query_indexes": r.get('query_indexes', [])
                                                            })
                                                            self.logger.info(f"ä»Ž API å¢žé‡æ›´æ–°æ•èŽ·ç½‘ç«™: {url[:60]}... (åŸŸå: {domain}, cite_index: {r.get('cite_index', 0)})")
                                                    
                                                    if len(captured_search_results) > results_before:
                                                        self.logger.info(f"å½“å‰å·²æ•èŽ·: {len(captured_queries)} ä¸ªæŸ¥è¯¢, {len(captured_search_results)} ä¸ªç½‘ç«™")
                                                
                                                # å¤„ç†å¢žé‡æ›´æ–°çš„ queries: {"p":"response/fragments/-1/queries","v":[...]}
                                                elif 'queries' in path.lower() or (len(data['v']) > 0 and not isinstance(data['v'][0], dict)):
                                                    queries_before = len(captured_queries)
                                                    for q in data['v']:
                                                        if isinstance(q, dict):
                                                            query_text = q.get('query', q.get('text', ''))
                                                        else:
                                                            query_text = str(q)
                                                        if query_text and query_text not in captured_queries:
                                                            captured_queries.append(query_text)
                                                            self.logger.info(f"ä»Ž API å¢žé‡æ›´æ–°æ•èŽ·æŸ¥è¯¢: \"{query_text}\"")
                                                    
                                                    if len(captured_queries) > queries_before:
                                                        self.logger.info(f"å½“å‰å·²æ•èŽ·: {len(captured_queries)} ä¸ªæŸ¥è¯¢, {len(captured_search_results)} ä¸ªç½‘ç«™")
                                        
                                        # å°è¯•å…¶ä»–å¯èƒ½çš„æ•°æ®ç»“æž„
                                        # ç›´æŽ¥åŒ…å« results æˆ– queries
                                        if 'results' in data and isinstance(data['results'], list):
                                            results_before = len(captured_search_results)
                                            for r in data['results']:
                                                if isinstance(r, dict) and r.get('url'):
                                                    url = r.get('url', '')
                                                    domain = extract_domain(url)
                                                    captured_search_results.append({
                                                        "url": url,
                                                        "title": r.get('title', r.get('name', '')),
                                                        "snippet": r.get('snippet', r.get('description', '')),
                                                        "site_name": r.get('site_name', r.get('source', '')),
                                                        "cite_index": r.get('cite_index', r.get('index', 0)),
                                                        "query_indexes": r.get('query_indexes', [])
                                                    })
                                                    self.logger.info(f"ä»Ž SSE (resultså­—æ®µ) æå–åˆ°ç½‘ç«™: {url[:60]}... (åŸŸå: {domain})")
                                            
                                            if len(captured_search_results) > results_before:
                                                self.logger.info(f"å½“å‰å·²æ•èŽ·: {len(captured_queries)} ä¸ªæŸ¥è¯¢, {len(captured_search_results)} ä¸ªç½‘ç«™")
                                        
                                        if 'queries' in data and isinstance(data['queries'], list):
                                            queries_before = len(captured_queries)
                                            for q in data['queries']:
                                                if isinstance(q, dict):
                                                    query_text = q.get('query', q.get('text', ''))
                                                else:
                                                    query_text = str(q)
                                                if query_text and query_text not in captured_queries:
                                                    captured_queries.append(query_text)
                                                    self.logger.info(f"ä»Ž SSE (querieså­—æ®µ) æå–åˆ°æŸ¥è¯¢: \"{query_text}\"")
                                            
                                            if len(captured_queries) > queries_before:
                                                self.logger.info(f"å½“å‰å·²æ•èŽ·: {len(captured_queries)} ä¸ªæŸ¥è¯¢, {len(captured_search_results)} ä¸ªç½‘ç«™")
                                        
                                        # æå–å›žç­”å†…å®¹
                                        if 'content' in data:
                                            content = data.get('content', '')
                                            if isinstance(content, str) and content:
                                                full_response_text += content
                                        elif 'delta' in data and 'content' in data.get('delta', {}):
                                            content = data['delta'].get('content', '')
                                            if isinstance(content, str) and content:
                                                full_response_text += content
                                                
                                except json.JSONDecodeError as e:
                                    self.logger.debug(f"JSON è§£æžå¤±è´¥: {e}")
                                    continue
                        except Exception as e:
                            self.logger.debug(f"è§£æž SSE å“åº”å¤±è´¥: {e}")
                    
                    # å¤„ç†æ™®é€š JSON å“åº”
                    elif "application/json" in content_type:
                        try:
                            data = response.json()
                            self.logger.debug(f"æ‹¦æˆªåˆ° JSON å“åº”: {response.url[:100]}")
                            
                            # æå–æœç´¢ç›¸å…³ä¿¡æ¯
                            if 'search' in data:
                                search_data = data['search']
                                if 'queries' in search_data:
                                    queries = search_data['queries']
                                    queries_before = len(captured_queries)
                                    if isinstance(queries, list):
                                        for q in queries:
                                            query_text = q if isinstance(q, str) else q.get('query', '')
                                            if query_text and query_text not in captured_queries:
                                                captured_queries.append(query_text)
                                                self.logger.info(f"ä»Ž JSON å“åº”æå–åˆ°æŸ¥è¯¢: \"{query_text}\"")
                                    
                                    if len(captured_queries) > queries_before:
                                        self.logger.info(f"å½“å‰å·²æ•èŽ·: {len(captured_queries)} ä¸ªæŸ¥è¯¢, {len(captured_search_results)} ä¸ªç½‘ç«™")
                                
                                if 'results' in search_data:
                                    results_before = len(captured_search_results)
                                    for r in search_data['results']:
                                        if isinstance(r, dict) and r.get('url'):
                                            url = r.get('url', '')
                                            domain = extract_domain(url)
                                            captured_search_results.append({
                                                "url": url,
                                                "title": r.get('title', ''),
                                                "snippet": r.get('snippet', ''),
                                                "site_name": r.get('site_name', r.get('source', '')),
                                                "cite_index": r.get('cite_index', r.get('index', 0)),
                                                "query_indexes": r.get('query_indexes', [])
                                            })
                                            self.logger.info(f"ä»Ž JSON å“åº”æå–åˆ°ç½‘ç«™: {url[:60]}... (åŸŸå: {domain})")
                                    
                                    if len(captured_search_results) > results_before:
                                        self.logger.info(f"å½“å‰å·²æ•èŽ·: {len(captured_queries)} ä¸ªæŸ¥è¯¢, {len(captured_search_results)} ä¸ªç½‘ç«™")
                        except Exception as e:
                            self.logger.debug(f"è§£æž JSON å“åº”å¤±è´¥: {e}")
                            
                except Exception as e:
                    self.logger.debug(f"æ‹¦æˆªå“åº”å¤±è´¥: {e}")
        
        with sync_playwright() as p:
            browser = p.chromium.launch_persistent_context(
                user_data_dir=user_data_dir,
                headless=self.headless,
                args=["--disable-blink-features=AutomationControlled"]
            )
            
            try:
                page = browser.pages[0] if browser.pages else browser.new_page()
                page.set_default_timeout(self.timeout)
                
                # æ³¨å†Œå“åº”æ‹¦æˆªå™¨
                page.on("response", handle_response)
                
                self.logger.info("æ­£åœ¨æ‰“å¼€ DeepSeek é¦–é¡µ...")
                page.goto("https://chat.deepseek.com/")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•
                time.sleep(2)
                if "login" in page.url or page.query_selector("text=ç™»å½•"):
                    self.logger.warning("æ£€æµ‹åˆ°å¯èƒ½éœ€è¦ç™»å½•ï¼Œè¯·åœ¨æµè§ˆå™¨çª—å£ä¸­å®Œæˆç™»å½•...")
                    try:
                        page.wait_for_url("**/chat.deepseek.com/**", timeout=120000)
                    except:
                        self.logger.error("ç™»å½•è¶…æ—¶ï¼Œè¯·ç¡®ä¿å·²æ‰‹åŠ¨ç™»å½•å¹¶ä¿å­˜çŠ¶æ€ã€‚")
                
                # 1. ç­‰å¾…è¾“å…¥æ¡†åŠ è½½å¹¶è¾“å…¥
                page.wait_for_selector("textarea", timeout=self.timeout)
                page.click("textarea")
                time.sleep(0.5)
                page.fill("textarea", prompt)
                self.logger.info(f"å·²è¾“å…¥æé—®: {prompt[:50]}...")
                time.sleep(1)
                
                # 2. å¼€å¯"è”ç½‘æœç´¢" - æ™ºèƒ½åˆ¤æ–­çŠ¶æ€
                try:
                    # å°è¯•å¤šç§å¯èƒ½çš„æœç´¢å¼€å…³é€‰æ‹©å™¨
                    search_toggle_selectors = [
                        "div:has-text('è”ç½‘æœç´¢')",
                        "button:has-text('è”ç½‘æœç´¢')",
                        "[aria-label*='è”ç½‘']",
                        "[title*='è”ç½‘']",
                        "div[class*='search']",
                        "div[class*='toggle']"
                    ]
                    
                    search_toggle = None
                    for selector in search_toggle_selectors:
                        try:
                            toggle = page.locator(selector).last
                            if toggle.is_visible():
                                search_toggle = toggle
                                self.logger.info(f"æ‰¾åˆ°è”ç½‘æœç´¢æŒ‰é’®ï¼Œé€‰æ‹©å™¨: {selector}")
                                break
                        except:
                            continue
                    
                    if search_toggle:
                        # æ£€æŸ¥æ˜¯å¦å·²ç»æ¿€æ´»
                        is_active = False
                        
                        # æ–¹æ¡ˆ A: æ£€æŸ¥ class ä¸­æ˜¯å¦åŒ…å«æ¿€æ´»çŠ¶æ€
                        try:
                            class_attr = search_toggle.get_attribute("class") or ""
                            parent_class = ""
                            try:
                                parent_class = page.evaluate("el => el.parentElement?.className || ''", search_toggle.element_handle())
                            except:
                                pass
                            
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¿€æ´»ç›¸å…³çš„å…³é”®å­—
                            if any(keyword in (class_attr + parent_class).lower() for keyword in ["checked", "active", "on", "enabled", "selected"]):
                                is_active = True
                                self.logger.debug(f"é€šè¿‡ class åˆ¤æ–­ï¼šå·²æ¿€æ´» (class: {class_attr}, parent: {parent_class})")
                            
                            # æ–¹æ¡ˆ B: æ£€æŸ¥é¢œè‰²æˆ–æ ·å¼
                            if not is_active:
                                try:
                                    color = page.evaluate("el => window.getComputedStyle(el).color", search_toggle.element_handle())
                                    bg_color = page.evaluate("el => window.getComputedStyle(el).backgroundColor", search_toggle.element_handle())
                                    # DeepSeek æ¿€æ´»æ—¶é€šå¸¸æ˜¯è“è‰² #247fff (rgb(36, 127, 255))
                                    if "rgb(36, 127, 255)" in color or "rgb(36, 127, 255)" in bg_color:
                                        is_active = True
                                        self.logger.debug(f"é€šè¿‡é¢œè‰²åˆ¤æ–­ï¼šå·²æ¿€æ´» (color: {color}, bg: {bg_color})")
                                    # å¦‚æžœé¢œè‰²ä¸æ˜¯é»˜è®¤çš„ç°è‰²/é»‘è‰²ï¼Œå¯èƒ½å·²æ¿€æ´»
                                    elif "rgb(0, 0, 0)" not in color and "rgb(128" not in color and color:
                                        # è¿›ä¸€æ­¥æ£€æŸ¥ï¼šå¦‚æžœæ–‡å­—é¢œè‰²æ˜Žæ˜¾ä¸æ˜¯ç°è‰²ï¼Œå¯èƒ½æ˜¯æ¿€æ´»çŠ¶æ€
                                        if "rgb(36" in color or "rgb(24" in color:  # è“è‰²ç³»
                                            is_active = True
                                            self.logger.debug(f"é€šè¿‡é¢œè‰²åˆ¤æ–­ï¼ˆè“è‰²ç³»ï¼‰ï¼šå·²æ¿€æ´» (color: {color})")
                                except Exception as color_error:
                                    self.logger.debug(f"æ£€æŸ¥é¢œè‰²å¤±è´¥: {color_error}")
                            
                            # æ–¹æ¡ˆ C: å¦‚æžœæ— æ³•ç¡®å®šï¼Œæ£€æŸ¥çˆ¶çº§æˆ–åŒçº§å…ƒç´ çš„æ¿€æ´»çŠ¶æ€
                            if not is_active:
                                try:
                                    # æŸ¥æ‰¾çˆ¶çº§å®¹å™¨ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»æ ‡è®°
                                    parent_active = page.evaluate("""
                                        el => {
                                            let parent = el.closest('[class*="toggle"], [class*="switch"], [class*="button"]');
                                            if (!parent) return false;
                                            let className = parent.className || '';
                                            return /checked|active|on|enabled|selected/i.test(className);
                                        }
                                    """, search_toggle.element_handle())
                                    if parent_active:
                                        is_active = True
                                        self.logger.debug("é€šè¿‡çˆ¶çº§å…ƒç´ åˆ¤æ–­ï¼šå·²æ¿€æ´»")
                                except:
                                    pass

                            if is_active:
                                self.logger.info("âœ… æ£€æµ‹åˆ°'è”ç½‘æœç´¢'å·²é»˜è®¤å¼€å¯ï¼Œè·³è¿‡ç‚¹å‡»ã€‚")
                            else:
                                # å¦‚æžœæ— æ³•ç¡®å®šçŠ¶æ€ï¼Œæˆ–è€…ç¡®å®šæœªæ¿€æ´»ï¼Œåˆ™ç‚¹å‡»å¼€å¯
                                self.logger.info("ðŸ”„ è”ç½‘æœç´¢æœªå¼€å¯ï¼Œæ­£åœ¨ç‚¹å‡»å¼€å¯...")
                                search_toggle.click()
                                time.sleep(0.8)  # ç­‰å¾…çŠ¶æ€æ›´æ–°
                                self.logger.info("âœ… å·²æ‰‹åŠ¨å¼€å¯'è”ç½‘æœç´¢'")
                        except Exception as check_error:
                            self.logger.warning(f"åˆ¤æ–­æœç´¢å¼€å…³çŠ¶æ€å¤±è´¥: {check_error}ï¼Œå°†å¼ºåˆ¶ç‚¹å‡»ä»¥ç¡®ä¿å¼€å¯")
                            # å¦‚æžœåˆ¤æ–­å¤±è´¥ï¼Œä¸ºäº†ç¡®ä¿æŒ‰é’®å¼€å¯ï¼Œå¼ºåˆ¶ç‚¹å‡»
                            try:
                                search_toggle.click()
                                time.sleep(0.8)
                                self.logger.info("âœ… å·²å¼ºåˆ¶ç‚¹å‡»å¼€å¯'è”ç½‘æœç´¢'ï¼ˆåˆ¤æ–­å¤±è´¥åŽçš„å®‰å…¨æŽªæ–½ï¼‰")
                            except:
                                pass
                    else:
                        # å¦‚æžœæ‰¾ä¸åˆ°æŒ‰é’®ï¼Œè®°å½•è­¦å‘Šï¼Œä½†ä¸é˜»å¡žæµç¨‹
                        self.logger.warning("âš ï¸ æœªæ‰¾åˆ°'è”ç½‘æœç´¢'æŒ‰é’®ï¼Œå¯èƒ½é¡µé¢ç»“æž„å·²å˜æ›´æˆ–æŒ‰é’®å·²é»˜è®¤å¼€å¯")
                except Exception as e:
                    self.logger.warning(f"å¤„ç†è”ç½‘æœç´¢å¼€å…³å¤±è´¥: {e}ï¼Œç»§ç»­æ‰§è¡Œï¼ˆå¯èƒ½æŒ‰é’®å·²é»˜è®¤å¼€å¯ï¼‰")
                
                # 3. ç‚¹å‡»å‘é€æŒ‰é’®
                try:
                    # æ ¹æ®æœ€æ–° UIï¼Œå‘é€æŒ‰é’®æ˜¯ä¸€ä¸ªè“è‰²çš„åœ†å½¢å›¾æ ‡æŒ‰é’®
                    # å°è¯•å¤šä¸ªå¯èƒ½çš„é€‰æ‹©å™¨
                    send_selectors = [
                        "div[class*='_7436f3']", # å¸¸è§çš„ç±»åæ¨¡å¼
                        "button:has(svg)",       # åŒ…å«å›¾æ ‡çš„æŒ‰é’®
                        ".ds-icon--send",        # å›¾æ ‡ç±»å
                        "div[role='button'] >> svg" # è§’è‰²ä¸ºæŒ‰é’®çš„ div ä¸‹çš„ svg
                    ]
                    
                    sent = False
                    for selector in send_selectors:
                        btn = page.locator(selector).last
                        if btn.is_visible() and btn.is_enabled():
                            btn.click()
                            sent = True
                            self.logger.info(f"é€šè¿‡é€‰æ‹©å™¨ {selector} ç‚¹å‡»äº†å‘é€æŒ‰é’®")
                            break
                    
                    if not sent:
                        # å¤‡é€‰ï¼šä½¿ç”¨é”®ç›˜å¿«æ·é”®
                        page.keyboard.press("Enter") # æˆ–è€… Control+Enter
                        self.logger.info("å·²é€šè¿‡ Enter é”®å‘é€")
                        
                except Exception as e:
                    self.logger.warning(f"ç‚¹å‡»å‘é€æŒ‰é’®å¤±è´¥: {e}")
                    page.keyboard.press("Control+Enter")
                
                self.logger.info("å·²å‘é€æé—®ï¼Œç­‰å¾… AI å›žç­”...")
                
                # 4. ç­‰å¾…å›žç­”ç”Ÿæˆå®Œæˆ
                time.sleep(5)  # ç­‰å¾…è¯·æ±‚å‘é€
                
                # ç­‰å¾…å›žç­”å®¹å™¨å‡ºçŽ°
                content_selector = ".ds-markdown"
                try:
                    page.wait_for_selector(content_selector, timeout=self.timeout)
                except:
                    self.logger.warning("æœªå‘çŽ° .ds-markdown å®¹å™¨")
                
                # å¾ªçŽ¯æ£€æŸ¥ç”ŸæˆçŠ¶æ€
                max_retries = 30
                max_retry_attempts = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
                retry_count = 0  # å½“å‰é‡è¯•æ¬¡æ•°
                last_content = ""
                
                for i in range(max_retries):
                    time.sleep(2)
                    try:
                        # æ£€æµ‹æ˜¯å¦å‡ºçŽ°åˆ·æ–°æŒ‰é’®ï¼ˆå¤±è´¥çŠ¶æ€ï¼‰
                        refresh_button = None
                        # ä½¿ç”¨ JavaScript æŸ¥æ‰¾åˆ·æ–°æŒ‰é’®ï¼Œæ›´å¯é 
                        try:
                            refresh_button = page.evaluate_handle("""
                                () => {
                                    // æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„åˆ·æ–°æŒ‰é’®
                                    const buttons = document.querySelectorAll('div.ds-icon-button, div[role="button"].ds-icon-button');
                                    
                                    for (const btn of buttons) {
                                        // æ£€æŸ¥æ˜¯å¦åœ¨æ¶ˆæ¯å…ƒç´ ä¸­
                                        const inMessage = btn.closest('div.ds-message');
                                        if (!inMessage) continue;
                                        
                                        // æ£€æŸ¥æ˜¯å¦åŒ…å« SVG
                                        const svg = btn.querySelector('svg');
                                        if (!svg) continue;
                                        
                                        // æ£€æŸ¥ SVG è·¯å¾„æ˜¯å¦åŒ…å«åˆ·æ–°å›¾æ ‡çš„ç‰¹å¾
                                        const path = svg.querySelector('path');
                                        if (!path) continue;
                                        
                                        const pathData = path.getAttribute('d') || '';
                                        
                                        // æ£€æŸ¥è·¯å¾„æ˜¯å¦åŒ…å«åˆ·æ–°å›¾æ ‡çš„ç‰¹å¾ï¼ˆM1.27206 æˆ–ç±»ä¼¼çš„è·¯å¾„ï¼‰
                                        // åˆ·æ–°å›¾æ ‡çš„è·¯å¾„é€šå¸¸å¾ˆé•¿ä¸”åŒ…å«ç‰¹å®šçš„æ•°å€¼
                                        if (pathData && (pathData.includes('M1.27206') || pathData.includes('1.27206') || pathData.length > 200)) {
                                            // è¿›ä¸€æ­¥éªŒè¯ï¼šæ£€æŸ¥æ˜¯å¦å¯è§
                                            const style = window.getComputedStyle(btn);
                                            if (style.display !== 'none' && style.visibility !== 'hidden' && style.opacity !== '0') {
                                                return btn;
                                            }
                                        }
                                    }
                                    return null;
                                }
                            """)
                            
                            # å¦‚æžœæ‰¾åˆ°äº†æŒ‰é’®ï¼Œæ£€æŸ¥æ˜¯å¦çœŸçš„å­˜åœ¨
                            if refresh_button and refresh_button.as_element():
                                # éªŒè¯å…ƒç´ æ˜¯å¦ä»ç„¶å¯è§
                                try:
                                    element = refresh_button.as_element()
                                    if element and element.is_visible():
                                        refresh_button = element
                                    else:
                                        refresh_button = None
                                except:
                                    refresh_button = None
                            else:
                                refresh_button = None
                        except Exception as e:
                            self.logger.debug(f"æ£€æµ‹åˆ·æ–°æŒ‰é’®æ—¶å‡ºé”™: {e}")
                            refresh_button = None
                        
                        # å¦‚æžœæ£€æµ‹åˆ°åˆ·æ–°æŒ‰é’®ï¼Œè¯´æ˜Žå¤±è´¥äº†ï¼Œéœ€è¦é‡è¯•
                        if refresh_button:
                            retry_count += 1
                            self.logger.warning(f"âš ï¸ æ£€æµ‹åˆ°å¤±è´¥çŠ¶æ€ï¼ˆåˆ·æ–°æŒ‰é’®å‡ºçŽ°ï¼‰ï¼Œå¼€å§‹ç¬¬ {retry_count}/{max_retry_attempts} æ¬¡é‡è¯•...")
                            
                            if retry_count > max_retry_attempts:
                                self.logger.error(f"âŒ é‡è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™ ({max_retry_attempts} æ¬¡)ï¼Œåœæ­¢é‡è¯•")
                                raise Exception(f"DeepSeek å›žç­”ç”Ÿæˆå¤±è´¥ï¼Œå·²é‡è¯• {max_retry_attempts} æ¬¡")
                            
                            # ç‚¹å‡»åˆ·æ–°æŒ‰é’®
                            try:
                                refresh_button.click()
                                self.logger.info(f"ðŸ”„ å·²ç‚¹å‡»åˆ·æ–°æŒ‰é’®ï¼Œç­‰å¾…é‡æ–°ç”Ÿæˆ...")
                                time.sleep(3)  # ç­‰å¾…åˆ·æ–°åŽçš„å“åº”
                                
                                # é‡ç½®ç­‰å¾…çŠ¶æ€
                                last_content = ""
                                
                                # é‡æ–°ç­‰å¾…å›žç­”å®¹å™¨å‡ºçŽ°
                                try:
                                    page.wait_for_selector(content_selector, timeout=self.timeout)
                                except:
                                    self.logger.warning("é‡è¯•åŽæœªå‘çŽ° .ds-markdown å®¹å™¨ï¼Œç»§ç»­ç­‰å¾…...")
                                
                                continue  # ç»§ç»­å¾ªçŽ¯ï¼Œç­‰å¾…æ–°çš„å›žç­”ç”Ÿæˆ
                            except Exception as click_error:
                                self.logger.error(f"âŒ ç‚¹å‡»åˆ·æ–°æŒ‰é’®å¤±è´¥: {click_error}")
                                raise Exception(f"æ— æ³•ç‚¹å‡»åˆ·æ–°æŒ‰é’®è¿›è¡Œé‡è¯•: {click_error}")
                        
                        # å°è¯•èŽ·å–å½“å‰å†…å®¹
                        content_el = page.query_selector(content_selector)
                        if content_el:
                            current_content = content_el.inner_text()
                            
                            # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆå®Œæˆ
                            if len(current_content) > 100:
                                if current_content == last_content:
                                    # å†…å®¹ä¸å†å˜åŒ–ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰"åœæ­¢ç”Ÿæˆ"æŒ‰é’®
                                    stop_btn = page.query_selector("text=åœæ­¢ç”Ÿæˆ")
                                    if not stop_btn:
                                        if retry_count > 0:
                                            self.logger.info(f"âœ… å›žç­”ç”Ÿæˆå·²å®Œæˆï¼ˆç»è¿‡ {retry_count} æ¬¡é‡è¯•ï¼‰")
                                        else:
                                            self.logger.info("å›žç­”ç”Ÿæˆå·²å®Œæˆ")
                                        full_response_text = current_content
                                        break
                                
                            last_content = current_content
                            if retry_count > 0:
                                self.logger.info(f"æ­£åœ¨ç”Ÿæˆä¸­... (å½“å‰é•¿åº¦: {len(current_content)}, å·²æ•èŽ· {len(captured_search_results)} ä¸ªæœç´¢ç»“æžœ, é‡è¯•æ¬¡æ•°: {retry_count})")
                            else:
                                self.logger.info(f"æ­£åœ¨ç”Ÿæˆä¸­... (å½“å‰é•¿åº¦: {len(current_content)}, å·²æ•èŽ· {len(captured_search_results)} ä¸ªæœç´¢ç»“æžœ)")
                    except Exception as e:
                        # å¦‚æžœæ˜¯é‡è¯•æ¬¡æ•°è¶…é™çš„å¼‚å¸¸ï¼Œç›´æŽ¥æŠ›å‡º
                        if "é‡è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™" in str(e) or "æ— æ³•ç‚¹å‡»åˆ·æ–°æŒ‰é’®" in str(e):
                            raise
                        continue
                
                # 5. æ•°æ®å·²ä»Žç½‘ç»œæŽ¥å£æŠ“å–å®Œæˆï¼Œä¼˜å…ˆä½¿ç”¨æŽ¥å£æ•°æ®
                if len(captured_search_results) == 0:
                    self.logger.warning("æœªé€šè¿‡ API æŽ¥å£æŠ“å–åˆ°å¼•ç”¨ï¼Œå°è¯•ä»Ž DOM æå–ä½œä¸ºè¡¥å……...")
                    api_captured_urls = set()
                else:
                    self.logger.info(f"å·²é€šè¿‡ API æŽ¥å£æŠ“å–åˆ° {len(captured_search_results)} ä¸ªå¼•ç”¨")
                    api_captured_urls = {r.get('url', '') for r in captured_search_results if r.get('url')}
                
                # å¦‚æžœæŽ¥å£æ²¡æœ‰æŠ“å–åˆ°æ•°æ®ï¼Œå°è¯•ä»Ž DOM æå–ä½œä¸ºæœ€åŽæ‰‹æ®µ
                if len(captured_search_results) == 0:
                    try:
                        # å°è¯•å¤šç§æ–¹å¼æå–å¼•ç”¨é“¾æŽ¥
                        # DeepSeek ä½¿ç”¨ ds-markdown-cite ç±»æ ‡è®°å¼•ç”¨
                        # ä¼˜å…ˆæå–å¸¦å¼•ç”¨æ ‡è®°çš„é“¾æŽ¥
                        link_selectors = [
                            ".ds-markdown a[href^='http'] .ds-markdown-cite",  # ä¼˜å…ˆï¼šå¸¦å¼•ç”¨æ ‡è®°çš„é“¾æŽ¥
                            ".ds-markdown a[href^='https'] .ds-markdown-cite",
                            ".ds-markdown a[href^='http']",  # markdown å†…å®¹ä¸­çš„æ‰€æœ‰é“¾æŽ¥
                            ".ds-markdown a[href^='https']",
                            "a[href^='http'] .ds-markdown-cite",  # æ‰€æœ‰å¸¦å¼•ç”¨æ ‡è®°çš„é“¾æŽ¥
                            "a[href^='https'] .ds-markdown-cite",
                            "a[href^='http']",  # æ‰€æœ‰å¤–éƒ¨é“¾æŽ¥
                            "a[href^='https']",
                            "[class*='citation'] a",  # å¼•ç”¨ç›¸å…³çš„é“¾æŽ¥
                            "[class*='reference'] a",
                            "[class*='source'] a",  # æ¥æºç›¸å…³çš„é“¾æŽ¥
                        ]
                        
                        seen_dom_urls = set(api_captured_urls)  # ä»Ž API å·²æ•èŽ·çš„ URL å¼€å§‹
                        dom_extracted_count = 0
                        
                        for selector in link_selectors:
                            try:
                                links = page.query_selector_all(selector)
                                self.logger.debug(f"é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(links)} ä¸ªé“¾æŽ¥")
                                
                                for link in links:
                                    try:
                                        # å¦‚æžœé€‰æ‹©å™¨åŒ¹é…çš„æ˜¯ .ds-markdown-citeï¼Œéœ€è¦æ‰¾åˆ°çˆ¶é“¾æŽ¥
                                        link_tag = link.evaluate("el => el.tagName.toLowerCase()")
                                        link_class = link.get_attribute("class") or ""
                                        
                                        if link_tag == 'span' or 'ds-markdown-cite' in link_class:
                                            # æ‰¾åˆ°çˆ¶çº§ a æ ‡ç­¾
                                            try:
                                                parent_a = link.evaluate_handle("el => el.closest('a')")
                                                if parent_a:
                                                    link = parent_a
                                                else:
                                                    # å¦‚æžœæ‰¾ä¸åˆ°çˆ¶ aï¼Œè·³è¿‡è¿™ä¸ªå…ƒç´ 
                                                    continue
                                            except:
                                                continue
                                        
                                        href = link.get_attribute("href")
                                        if not href:
                                            continue
                                        
                                        # è¿‡æ»¤æŽ‰ DeepSeek è‡ªå·±çš„åŸŸå
                                        if any(d in href.lower() for d in ["deepseek.com", "deepseek.ai"]):
                                            continue
                                        
                                        # åŽ»é‡
                                        if href in seen_dom_urls:
                                            continue
                                        seen_dom_urls.add(href)
                                        
                                        # æå–å¼•ç”¨åºå·ï¼ˆå…³é”®ä¿®å¤ï¼šä»Ž ds-markdown-cite ä¸­æå–ï¼‰
                                        cite_index = 0
                                        try:
                                            # æŸ¥æ‰¾é“¾æŽ¥å†…çš„ ds-markdown-cite å…ƒç´ 
                                            cite_element = link.query_selector(".ds-markdown-cite")
                                            if cite_element:
                                                # ä»Ž cite å…ƒç´ ä¸­æå–åºå·
                                                cite_text = cite_element.inner_text().strip()
                                                # å°è¯•ä»Žæ–‡æœ¬ä¸­æå–æ•°å­—ï¼ˆå¦‚ "1", "2"ï¼‰
                                                import re
                                                match = re.search(r'\d+', cite_text)
                                                if match:
                                                    cite_index = int(match.group())
                                                else:
                                                    # å°è¯•ä»Ž span çš„ç»å¯¹å®šä½å…ƒç´ ä¸­æå–
                                                    cite_number = cite_element.evaluate("""
                                                        el => {
                                                            let spans = el.querySelectorAll('span');
                                                            for (let span of spans) {
                                                                let text = span.textContent.trim();
                                                                let num = parseInt(text);
                                                                if (!isNaN(num) && num > 0) {
                                                                    return num;
                                                                }
                                                            }
                                                            return 0;
                                                        }
                                                    """)
                                                    cite_index = cite_number or 0
                                        except Exception as e:
                                            self.logger.debug(f"æå–å¼•ç”¨åºå·å¤±è´¥: {e}")
                                        
                                        # å¦‚æžœæ²¡æœ‰æ‰¾åˆ°åºå·ï¼Œå°è¯•ä»Žé“¾æŽ¥å‘¨å›´çš„æ–‡æœ¬ä¸­æå–
                                        if cite_index == 0:
                                            try:
                                                # æŸ¥æ‰¾é“¾æŽ¥å‰çš„å¼•ç”¨æ ‡è®°
                                                prev_text = link.evaluate("""
                                                    el => {
                                                        let text = el.textContent || '';
                                                        let match = text.match(/\\[(\\d+)\\]/);
                                                        if (match) return parseInt(match[1]);
                                                        
                                                        // æŸ¥æ‰¾çˆ¶å…ƒç´ ä¸­çš„å¼•ç”¨æ ‡è®°
                                                        let parent = el.parentElement;
                                                        if (parent) {
                                                            let parentText = parent.textContent || '';
                                                            let parentMatch = parentText.match(/\\[(\\d+)\\]/);
                                                            if (parentMatch) return parseInt(parentMatch[1]);
                                                        }
                                                        return 0;
                                                    }
                                                """)
                                                cite_index = prev_text or 0
                                            except:
                                                pass
                                        
                                        # å¦‚æžœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°åºå·ï¼Œä½¿ç”¨å½“å‰è®¡æ•°
                                        if cite_index == 0:
                                            cite_index = len(captured_search_results) + 1
                                        
                                        # æå–æ ‡é¢˜
                                        title = link.inner_text().strip()
                                        # ç§»é™¤å¼•ç”¨æ ‡è®°ï¼ˆå¦‚ [1]ï¼‰ä»Žæ ‡é¢˜ä¸­
                                        import re
                                        title = re.sub(r'\[\d+\]', '', title).strip()
                                        
                                        if not title:
                                            # å°è¯•ä»Žçˆ¶å…ƒç´ æˆ–é™„è¿‘å…ƒç´ èŽ·å–
                                            try:
                                                parent_text = link.evaluate("""
                                                    el => {
                                                        let parent = el.parentElement;
                                                        if (parent) {
                                                            let text = parent.textContent || '';
                                                            // ç§»é™¤å¼•ç”¨æ ‡è®°
                                                            text = text.replace(/\\[\\d+\\]/g, '').trim();
                                                            return text.substring(0, 100);
                                                        }
                                                        return '';
                                                    }
                                                """)
                                                title = parent_text
                                            except:
                                                pass
                                        
                                        # æå–æ‘˜è¦ï¼ˆå°è¯•ä»Žé™„è¿‘å…ƒç´ ï¼‰
                                        snippet = ""
                                        try:
                                            sibling_text = link.evaluate("""
                                                el => {
                                                    let next = el.nextElementSibling;
                                                    if (next && next.textContent) {
                                                        return next.textContent.trim().substring(0, 200);
                                                    }
                                                    let parent = el.parentElement;
                                                    if (parent && parent.nextElementSibling) {
                                                        return parent.nextElementSibling.textContent.trim().substring(0, 200);
                                                    }
                                                    return '';
                                                }
                                            """)
                                            snippet = sibling_text
                                        except:
                                            pass
                                        
                                        captured_search_results.append({
                                            "url": href,
                                            "title": title or extract_domain(href),
                                            "snippet": snippet,
                                            "site_name": extract_domain(href),
                                            "cite_index": cite_index
                                        })
                                        dom_extracted_count += 1
                                        self.logger.debug(f"ä»Ž DOM æ•èŽ·å¼•ç”¨: {href[:50]}... (cite_index: {cite_index})")
                                    except Exception as e:
                                        self.logger.debug(f"æå–é“¾æŽ¥å¤±è´¥: {e}")
                                        continue
                            except Exception as e:
                                self.logger.debug(f"é€‰æ‹©å™¨ '{selector}' æ‰§è¡Œå¤±è´¥: {e}")
                                continue
                    
                        self.logger.info(f"ä»Ž DOM æå–åˆ° {dom_extracted_count} ä¸ªæ–°å¼•ç”¨é“¾æŽ¥ï¼ˆAPI å·²æ•èŽ· {len(api_captured_urls)} ä¸ªï¼‰")
                        
                        # å°è¯•æŸ¥æ‰¾å¼•ç”¨åˆ—è¡¨åŒºåŸŸï¼ˆDeepSeek å¯èƒ½åœ¨åº•éƒ¨æˆ–ä¾§è¾¹æ˜¾ç¤ºå¼•ç”¨åˆ—è¡¨ï¼‰
                        try:
                            # æŸ¥æ‰¾å¯èƒ½çš„å¼•ç”¨åˆ—è¡¨å®¹å™¨
                            citation_containers = [
                                "[class*='citation']",
                                "[class*='reference']",
                                "[class*='source']",
                                "[class*='link-list']",
                                "[class*='reference-list']"
                            ]
                            
                            for container_selector in citation_containers:
                                try:
                                    containers = page.query_selector_all(container_selector)
                                    if containers:
                                        self.logger.debug(f"æ‰¾åˆ° {len(containers)} ä¸ªå¯èƒ½çš„å¼•ç”¨å®¹å™¨: {container_selector}")
                                        for container in containers:
                                            # åœ¨å®¹å™¨å†…æŸ¥æ‰¾é“¾æŽ¥
                                            container_links = container.query_selector_all("a[href^='http']")
                                            for link in container_links:
                                                try:
                                                    href = link.get_attribute("href")
                                                    if href and href not in seen_dom_urls:
                                                        seen_dom_urls.add(href)
                                                        title = link.inner_text().strip() or extract_domain(href)
                                                        captured_search_results.append({
                                                            "url": href,
                                                            "title": title,
                                                            "snippet": "",
                                                            "site_name": extract_domain(href),
                                                            "cite_index": len(captured_search_results) + 1
                                                        })
                                                        dom_extracted_count += 1
                                                except:
                                                    continue
                                except:
                                    continue
                        except Exception as e:
                            self.logger.debug(f"æŸ¥æ‰¾å¼•ç”¨åˆ—è¡¨å®¹å™¨å¤±è´¥: {e}")
                    except Exception as e:
                        self.logger.warning(f"ä»Ž DOM æå–å¼•ç”¨å¤±è´¥: {e}")
                
                # 6. æ•´ç†æœç´¢ç»“æžœï¼ˆåŽ»é‡ï¼‰
                seen_urls = set()
                unique_citations = []
                for result in captured_search_results:
                    url = result.get('url', '')
                    if url and url not in seen_urls:
                        seen_urls.add(url)
                        unique_citations.append({
                            "url": url,
                            "title": result.get('title', ''),
                            "snippet": result.get('snippet', ''),
                            "site_name": result.get('site_name', ''),
                            "cite_index": result.get('cite_index', 0),
                            "query_indexes": result.get('query_indexes', [])  # ä¿ç•™ query_indexes å­—æ®µ
                        })
                
                # æŒ‰ cite_index æŽ’åº
                unique_citations.sort(key=lambda x: x.get('cite_index', 999))
                
                # è®¡ç®—æ•°æ®æ¥æºç»Ÿè®¡
                api_captured_count = len(api_captured_urls)
                dom_extracted_count = len(unique_citations) - api_captured_count
                if dom_extracted_count < 0:
                    dom_extracted_count = 0
                
                # æ•°æ®æ•èŽ·æ±‡æ€»æ—¥å¿—
                self.logger.info("")
                self.logger.info("=" * 60)
                self.logger.info("ðŸ“Š æ•°æ®æ•èŽ·æ±‡æ€»")
                self.logger.info("=" * 60)
                
                # æŸ¥è¯¢ä¿¡æ¯æ±‡æ€»
                self.logger.info(f"ðŸ” æŸ¥è¯¢ä¿¡æ¯ (å…± {len(captured_queries)} ä¸ª):")
                if captured_queries:
                    for idx, q in enumerate(captured_queries, 1):
                        self.logger.info(f"  {idx}. \"{q}\"")
                else:
                    self.logger.info("  (æœªæ•èŽ·åˆ°æŸ¥è¯¢)")
                
                # ç½‘ç«™ä¿¡æ¯æ±‡æ€»
                self.logger.info("")
                self.logger.info(f"ðŸŒ æŠ“å–ç½‘ç«™ (å…± {len(unique_citations)} ä¸ªå”¯ä¸€ç½‘ç«™):")
                self.logger.info(f"  - API æ‹¦æˆª: {api_captured_count} ä¸ª")
                self.logger.info(f"  - DOM æå–: {dom_extracted_count} ä¸ª")
                
                if unique_citations:
                    # æŒ‰åŸŸååˆ†ç»„ç»Ÿè®¡
                    domain_count = {}
                    for cite in unique_citations:
                        domain = cite.get('site_name', 'unknown')
                        domain_count[domain] = domain_count.get(domain, 0) + 1
                    
                    self.logger.info("")
                    self.logger.info("  ç½‘ç«™åˆ—è¡¨ (å‰15ä¸ª):")
                    for cite in unique_citations[:15]:
                        cite_index = cite.get('cite_index', 0)
                        site_name = cite.get('site_name', 'unknown')
                        title = cite.get('title', '')[:40] or '(æ— æ ‡é¢˜)'
                        url = cite.get('url', '')[:50]
                        self.logger.info(f"    [{cite_index}] {site_name}: {title}... ({url}...)")
                    
                    if len(unique_citations) > 15:
                        self.logger.info(f"    ... è¿˜æœ‰ {len(unique_citations) - 15} ä¸ªç½‘ç«™æœªæ˜¾ç¤º")
                    
                    self.logger.info("")
                    self.logger.info("  åŸŸååˆ†å¸ƒ (å‰10ä¸ª):")
                    sorted_domains = sorted(domain_count.items(), key=lambda x: x[1], reverse=True)
                    for domain, count in sorted_domains[:10]:
                        self.logger.info(f"    {domain}: {count} æ¬¡")
                else:
                    self.logger.info("  (æœªæ•èŽ·åˆ°ç½‘ç«™)")
                
                self.logger.info("")
                self.logger.info("=" * 60)
                self.logger.info("âœ… æ•°æ®æ•èŽ·å®Œæˆ")
                self.logger.info(f"   - æŸ¥è¯¢: {len(captured_queries)} ä¸ª")
                self.logger.info(f"   - ç½‘ç«™: {len(unique_citations)} ä¸ª")
                self.logger.info("=" * 60)
                self.logger.info("")
                
                # å¦‚æžœæ•èŽ·æ•°é‡æ˜Žæ˜¾å°‘äºŽé¢„æœŸï¼Œè¾“å‡ºè°ƒè¯•ä¿¡æ¯
                if len(unique_citations) < 3:
                    self.logger.warning("âš ï¸ æ•èŽ·åˆ°çš„å¼•ç”¨æ•°é‡è¾ƒå°‘ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜")
                    self.logger.info("ðŸ’¡ è°ƒè¯•å»ºè®®ï¼š")
                    self.logger.info("   1. æ£€æŸ¥é¡µé¢ä¸­æ˜¯å¦ç¡®å®žæ˜¾ç¤ºäº†å¼•ç”¨é“¾æŽ¥")
                    self.logger.info("   2. æŸ¥çœ‹æµè§ˆå™¨å¼€å‘è€…å·¥å…·çš„ Network æ ‡ç­¾ï¼Œæ‰¾åˆ° API å“åº”")
                    self.logger.info("   3. æ£€æŸ¥é¡µé¢ HTML ä¸­å¼•ç”¨é“¾æŽ¥çš„å®žé™…ç»“æž„")
                
                return {
                    "full_text": full_response_text or last_content,
                    "queries": captured_queries,  # æ‹“å±•è¯
                    "citations": unique_citations  # å‚è€ƒç½‘é¡µ
                }
            finally:
                browser.close()
