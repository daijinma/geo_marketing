import time
import os
import json
import re
from playwright.sync_api import sync_playwright
from providers.base import BaseProvider
from core.parser import extract_domain
from core.logger_config import setup_logger

class DeepSeekWebProvider(BaseProvider):
    def search(self, keyword: str, prompt: str):
        user_data_dir = os.path.join(os.getenv("BROWSER_DATA_DIR", "./browser_data"), "deepseek")
        
        # Áî®‰∫éÂ≠òÂÇ®Êã¶Êà™Âà∞ÁöÑÊêúÁ¥¢ÁªìÊûú
        captured_search_results = []
        captured_queries = []  # Â≠òÂÇ® AI ÊãìÂ±ïÁöÑÊêúÁ¥¢ËØç
        full_response_text = ""
        
        def handle_response(response):
            """Êã¶Êà™ API ÂìçÂ∫îÔºåÊèêÂèñÊêúÁ¥¢ÁªìÊûúÂíåÊãìÂ±ïËØç"""
            nonlocal captured_search_results, captured_queries, full_response_text
            
            url_lower = response.url.lower()
            # Êâ©Â±ïAPIÁ´ØÁÇπÂåπÈÖçÊ®°Âºè
            api_patterns = [
                "api/v0/chat/completion",
                "api/v1/chat/completion"
            ]
            self.logger.info(f"[ÁΩëÁªúÊã¶Êà™] ÂìçÂ∫îURL: {response.url}")
            if any(pattern in url_lower for pattern in api_patterns):
                matched_pattern = next((p for p in api_patterns if p in url_lower), "unknown")
                self.logger.info(f"[ÁΩëÁªúÊã¶Êà™] APIÁ´ØÁÇπÂåπÈÖç: {matched_pattern}")
                try:
                    content_type = response.headers.get("content-type", "")
                    
                    # Â§ÑÁêÜ SSE ÊµÅ
                    if "text/event-stream" in content_type or "stream" in url_lower:
                        try:
                            body = response.text()
                            self.logger.info(f"[ÁΩëÁªúÊã¶Êà™] SSEÊµÅÂºèÂìçÂ∫îÔºåÂºÄÂßãËß£ÊûêÊï∞ÊçÆ")
                            
                            # Ê≠£Á°ÆËß£Êûê SSE Êï∞ÊçÆÊµÅ
                            # SSE Ê†ºÂºèÔºö‰∫ã‰ª∂‰πãÈó¥Áî®Á©∫Ë°åÂàÜÈöîÔºå‰∏Ä‰∏™‰∫ã‰ª∂ÂèØ‰ª•ÊúâÂ§öË°å data:
                            events = []
                            current_event_data = []
                            
                            for line in body.split('\n'):
                                line = line.rstrip('\r')  # ÁßªÈô§ÂèØËÉΩÁöÑ \r
                                
                                if line.startswith('data: '):
                                    # Êî∂ÈõÜÂ§öË°å data: Â≠óÊÆµ
                                    data_content = line[6:]  # ÂéªÊéâ "data: " ÂâçÁºÄ
                                    current_event_data.append(data_content)
                                elif line == '':
                                    # Á©∫Ë°åË°®Á§∫‰∫ã‰ª∂ÁªìÊùüÔºåÂêàÂπ∂ÊâÄÊúâ data: Ë°å
                                    if current_event_data:
                                        # Â§öË°å data: Â∫îËØ•Áî®Êç¢Ë°åÁ¨¶ËøûÊé•
                                        combined_data = '\n'.join(current_event_data)
                                        events.append(combined_data)
                                        current_event_data = []
                                elif line.startswith('event:') or line.startswith('id:') or line.startswith('retry:'):
                                    # ÂøΩÁï•ÂÖ∂‰ªñ SSE Â≠óÊÆµÔºàevent, id, retryÔºâ
                                    continue
                            
                            # Â§ÑÁêÜÊúÄÂêé‰∏Ä‰∏™‰∫ã‰ª∂ÔºàÂ¶ÇÊûúÊ≤°Êúâ‰ª•Á©∫Ë°åÁªìÂ∞æÔºâ
                            if current_event_data:
                                combined_data = '\n'.join(current_event_data)
                                events.append(combined_data)
                            
                            self.logger.debug(f"[SSEËß£Êûê] ÂÖ±Ëß£ÊûêÂà∞ {len(events)} ‰∏™ SSE ‰∫ã‰ª∂")
                            
                            # Â§ÑÁêÜÊØè‰∏™‰∫ã‰ª∂ÁöÑÊï∞ÊçÆ
                            for event_data in events:
                                try:
                                    json_str = event_data.strip()
                                    if json_str and json_str != '[DONE]' and json_str != 'null':
                                        data = json.loads(json_str)
                                        
                                        # ÊèêÂèñÊêúÁ¥¢ÁªìÊûúÂíåÊãìÂ±ïËØç
                                        if 'v' in data:
                                            # ÊÉÖÂÜµ1: ÂÆåÊï¥ÁöÑ fragments Êï∞ÊçÆ
                                            if isinstance(data['v'], dict):
                                                response_data = data['v'].get('response', {})
                                                fragments = response_data.get('fragments', [])
                                                for frag in fragments:
                                                    if frag.get('type') == 'SEARCH':
                                                        # ÊèêÂèñÊãìÂ±ïËØç (queries)
                                                        queries = frag.get('queries', [])
                                                        queries_before = len(captured_queries)
                                                        for q in queries:
                                                            if isinstance(q, dict):
                                                                query_text = q.get('query', q.get('text', ''))
                                                            else:
                                                                query_text = str(q)
                                                            if query_text and query_text not in captured_queries:
                                                                captured_queries.append(query_text)
                                                                self.logger.info(f"[Êï∞ÊçÆÊäìÂèñ] Êü•ËØ¢ËØç: {query_text}")
                                                        
                                                        if len(captured_queries) > queries_before:
                                                            self.logger.info(f"[Êï∞ÊçÆÊäìÂèñ] ËøõÂ∫¶: {len(captured_queries)} ‰∏™Êü•ËØ¢, {len(captured_search_results)} ‰∏™ÁΩëÁ´ô")
                                                        
                                                        # ÊèêÂèñÊêúÁ¥¢ÁªìÊûú (results)
                                                        results = frag.get('results', [])
                                                        results_before = len(captured_search_results)
                                                        for r in results:
                                                            if isinstance(r, dict) and r.get('url'):
                                                                url = r.get('url', '')
                                                                domain = extract_domain(url)
                                                                captured_search_results.append({
                                                                    "url": url,
                                                                    "title": r.get('title', r.get('name', '')),
                                                                    "snippet": r.get('snippet', r.get('description', '')),
                                                                    "site_name": r.get('site_name', r.get('source', '')),
                                                                    "cite_index": r.get('cite_index', r.get('index', 0))
                                                                })
                                                                self.logger.info(f"[Êï∞ÊçÆÊäìÂèñ] ÁΩëÁ´ô: {url[:60]}... (ÂüüÂêç: {domain})")
                                                        
                                                        if len(captured_search_results) > results_before:
                                                            self.logger.info(f"[Êï∞ÊçÆÊäìÂèñ] ËøõÂ∫¶: {len(captured_queries)} ‰∏™Êü•ËØ¢, {len(captured_search_results)} ‰∏™ÁΩëÁ´ô")
                                            
                                            # ÊÉÖÂÜµ2: Â¢ûÈáèÊõ¥Êñ∞ÁöÑ results Êï∞ÁªÑÔºàÂÖ≥ÈîÆ‰øÆÂ§çÔºâ
                                            elif isinstance(data['v'], list):
                                                # Ê£ÄÊü•Ë∑ØÂæÑÂèÇÊï∞ÔºåÁ°ÆËÆ§ÊòØÂê¶ÊòØ results Êõ¥Êñ∞
                                                path = data.get('p', '')
                                                
                                                # Â§ÑÁêÜÂ¢ûÈáèÊõ¥Êñ∞ÁöÑ results: {"p":"response/fragments/-1/results","v":[...]}
                                                if 'results' in path.lower() or (len(data['v']) > 0 and isinstance(data['v'][0], dict) and 'url' in data['v'][0]):
                                                    results_before = len(captured_search_results)
                                                    for r in data['v']:
                                                        if isinstance(r, dict) and r.get('url'):
                                                            url = r.get('url', '')
                                                            domain = extract_domain(url)
                                                            captured_search_results.append({
                                                                "url": url,
                                                                "title": r.get('title', r.get('name', '')),
                                                                "snippet": r.get('snippet', r.get('description', '')),
                                                                "site_name": r.get('site_name', r.get('source', '')),
                                                                "cite_index": r.get('cite_index', r.get('index', 0))
                                                            })
                                                            self.logger.info(f"‰ªé API Â¢ûÈáèÊõ¥Êñ∞ÊçïËé∑ÁΩëÁ´ô: {url[:60]}... (ÂüüÂêç: {domain}, cite_index: {r.get('cite_index', 0)})")
                                                    
                                                    if len(captured_search_results) > results_before:
                                                        self.logger.info(f"ÂΩìÂâçÂ∑≤ÊçïËé∑: {len(captured_queries)} ‰∏™Êü•ËØ¢, {len(captured_search_results)} ‰∏™ÁΩëÁ´ô")
                                                
                                                # Â§ÑÁêÜÂ¢ûÈáèÊõ¥Êñ∞ÁöÑ queries: {"p":"response/fragments/-1/queries","v":[...]}
                                                elif 'queries' in path.lower() or (len(data['v']) > 0 and not isinstance(data['v'][0], dict)):
                                                    queries_before = len(captured_queries)
                                                    for q in data['v']:
                                                        if isinstance(q, dict):
                                                            query_text = q.get('query', q.get('text', ''))
                                                        else:
                                                            query_text = str(q)
                                                        if query_text and query_text not in captured_queries:
                                                            captured_queries.append(query_text)
                                                            self.logger.info(f"‰ªé API Â¢ûÈáèÊõ¥Êñ∞ÊçïËé∑Êü•ËØ¢: \"{query_text}\"")
                                                    
                                                    if len(captured_queries) > queries_before:
                                                        self.logger.info(f"ÂΩìÂâçÂ∑≤ÊçïËé∑: {len(captured_queries)} ‰∏™Êü•ËØ¢, {len(captured_search_results)} ‰∏™ÁΩëÁ´ô")
                                        
                                        # Â∞ùËØïÂÖ∂‰ªñÂèØËÉΩÁöÑÊï∞ÊçÆÁªìÊûÑ
                                        # Áõ¥Êé•ÂåÖÂê´ results Êàñ queries
                                        if 'results' in data and isinstance(data['results'], list):
                                            results_before = len(captured_search_results)
                                            for r in data['results']:
                                                if isinstance(r, dict) and r.get('url'):
                                                    url = r.get('url', '')
                                                    domain = extract_domain(url)
                                                    captured_search_results.append({
                                                        "url": url,
                                                        "title": r.get('title', r.get('name', '')),
                                                        "snippet": r.get('snippet', r.get('description', '')),
                                                        "site_name": r.get('site_name', r.get('source', '')),
                                                        "cite_index": r.get('cite_index', r.get('index', 0))
                                                    })
                                                    self.logger.info(f"‰ªé SSE (resultsÂ≠óÊÆµ) ÊèêÂèñÂà∞ÁΩëÁ´ô: {url[:60]}... (ÂüüÂêç: {domain})")
                                            
                                            if len(captured_search_results) > results_before:
                                                self.logger.info(f"ÂΩìÂâçÂ∑≤ÊçïËé∑: {len(captured_queries)} ‰∏™Êü•ËØ¢, {len(captured_search_results)} ‰∏™ÁΩëÁ´ô")
                                        
                                        if 'queries' in data and isinstance(data['queries'], list):
                                            queries_before = len(captured_queries)
                                            for q in data['queries']:
                                                if isinstance(q, dict):
                                                    query_text = q.get('query', q.get('text', ''))
                                                else:
                                                    query_text = str(q)
                                                if query_text and query_text not in captured_queries:
                                                    captured_queries.append(query_text)
                                                    self.logger.info(f"‰ªé SSE (queriesÂ≠óÊÆµ) ÊèêÂèñÂà∞Êü•ËØ¢: \"{query_text}\"")
                                            
                                            if len(captured_queries) > queries_before:
                                                self.logger.info(f"ÂΩìÂâçÂ∑≤ÊçïËé∑: {len(captured_queries)} ‰∏™Êü•ËØ¢, {len(captured_search_results)} ‰∏™ÁΩëÁ´ô")
                                        
                                        # ÊèêÂèñÂõûÁ≠îÂÜÖÂÆπ
                                        if 'content' in data:
                                            content = data.get('content', '')
                                            if isinstance(content, str) and content:
                                                full_response_text += content
                                        elif 'delta' in data and 'content' in data.get('delta', {}):
                                            content = data['delta'].get('content', '')
                                            if isinstance(content, str) and content:
                                                full_response_text += content
                                                
                                except json.JSONDecodeError as e:
                                    self.logger.debug(f"JSON Ëß£ÊûêÂ§±Ë¥•: {e}")
                                    continue
                        except Exception as e:
                            self.logger.debug(f"Ëß£Êûê SSE ÂìçÂ∫îÂ§±Ë¥•: {e}")
                    
                    # Â§ÑÁêÜÊôÆÈÄö JSON ÂìçÂ∫î
                    elif "application/json" in content_type:
                        try:
                            data = response.json()
                            self.logger.debug(f"Êã¶Êà™Âà∞ JSON ÂìçÂ∫î: {response.url[:100]}")
                            
                            # ÊèêÂèñÊêúÁ¥¢Áõ∏ÂÖ≥‰ø°ÊÅØ
                            if 'search' in data:
                                search_data = data['search']
                                if 'queries' in search_data:
                                    queries = search_data['queries']
                                    queries_before = len(captured_queries)
                                    if isinstance(queries, list):
                                        for q in queries:
                                            query_text = q if isinstance(q, str) else q.get('query', '')
                                            if query_text and query_text not in captured_queries:
                                                captured_queries.append(query_text)
                                                self.logger.info(f"‰ªé JSON ÂìçÂ∫îÊèêÂèñÂà∞Êü•ËØ¢: \"{query_text}\"")
                                    
                                    if len(captured_queries) > queries_before:
                                        self.logger.info(f"ÂΩìÂâçÂ∑≤ÊçïËé∑: {len(captured_queries)} ‰∏™Êü•ËØ¢, {len(captured_search_results)} ‰∏™ÁΩëÁ´ô")
                                
                                if 'results' in search_data:
                                    results_before = len(captured_search_results)
                                    for r in search_data['results']:
                                        if isinstance(r, dict) and r.get('url'):
                                            url = r.get('url', '')
                                            domain = extract_domain(url)
                                            captured_search_results.append({
                                                "url": url,
                                                "title": r.get('title', ''),
                                                "snippet": r.get('snippet', ''),
                                                "site_name": r.get('site_name', r.get('source', '')),
                                                "cite_index": r.get('cite_index', r.get('index', 0))
                                            })
                                            self.logger.info(f"‰ªé JSON ÂìçÂ∫îÊèêÂèñÂà∞ÁΩëÁ´ô: {url[:60]}... (ÂüüÂêç: {domain})")
                                    
                                    if len(captured_search_results) > results_before:
                                        self.logger.info(f"ÂΩìÂâçÂ∑≤ÊçïËé∑: {len(captured_queries)} ‰∏™Êü•ËØ¢, {len(captured_search_results)} ‰∏™ÁΩëÁ´ô")
                        except Exception as e:
                            self.logger.debug(f"Ëß£Êûê JSON ÂìçÂ∫îÂ§±Ë¥•: {e}")
                            
                except Exception as e:
                    self.logger.debug(f"Êã¶Êà™ÂìçÂ∫îÂ§±Ë¥•: {e}")
        
        with sync_playwright() as p:
            browser = p.chromium.launch_persistent_context(
                user_data_dir=user_data_dir,
                headless=self.headless,
                args=["--disable-blink-features=AutomationControlled"]
            )
            
            try:
                page = browser.pages[0] if browser.pages else browser.new_page()
                page.set_default_timeout(self.timeout)
                
                # Ê≥®ÂÜåÂìçÂ∫îÊã¶Êà™Âô®
                page.on("response", handle_response)
                
                self.logger.info("Ê≠£Âú®ÊâìÂºÄ DeepSeek È¶ñÈ°µ...")
                page.goto("https://chat.deepseek.com/")
                
                # Ê£ÄÊü•ÊòØÂê¶ÈúÄË¶ÅÁôªÂΩï
                time.sleep(2)
                if "login" in page.url or page.query_selector("text=ÁôªÂΩï"):
                    self.logger.warning("Ê£ÄÊµãÂà∞ÂèØËÉΩÈúÄË¶ÅÁôªÂΩïÔºåËØ∑Âú®ÊµèËßàÂô®Á™óÂè£‰∏≠ÂÆåÊàêÁôªÂΩï...")
                    try:
                        page.wait_for_url("**/chat.deepseek.com/**", timeout=120000)
                    except:
                        self.logger.error("ÁôªÂΩïË∂ÖÊó∂ÔºåËØ∑Á°Æ‰øùÂ∑≤ÊâãÂä®ÁôªÂΩïÂπ∂‰øùÂ≠òÁä∂ÊÄÅ„ÄÇ")
                
                # 1. Á≠âÂæÖËæìÂÖ•Ê°ÜÂä†ËΩΩÂπ∂ËæìÂÖ•
                page.wait_for_selector("textarea", timeout=self.timeout)
                page.click("textarea")
                time.sleep(0.5)
                page.fill("textarea", prompt)
                self.logger.info(f"Â∑≤ËæìÂÖ•ÊèêÈóÆ: {prompt[:50]}...")
                time.sleep(1)
                
                # 2. ÂºÄÂêØ"ËÅîÁΩëÊêúÁ¥¢" - Êô∫ËÉΩÂà§Êñ≠Áä∂ÊÄÅ
                try:
                    # Â∞ùËØïÂ§öÁßçÂèØËÉΩÁöÑÊêúÁ¥¢ÂºÄÂÖ≥ÈÄâÊã©Âô®
                    search_toggle_selectors = [
                        "div:has-text('ËÅîÁΩëÊêúÁ¥¢')",
                        "button:has-text('ËÅîÁΩëÊêúÁ¥¢')",
                        "[aria-label*='ËÅîÁΩë']",
                        "[title*='ËÅîÁΩë']",
                        "div[class*='search']",
                        "div[class*='toggle']"
                    ]
                    
                    search_toggle = None
                    for selector in search_toggle_selectors:
                        try:
                            toggle = page.locator(selector).last
                            if toggle.is_visible():
                                search_toggle = toggle
                                self.logger.info(f"ÊâæÂà∞ËÅîÁΩëÊêúÁ¥¢ÊåâÈíÆÔºåÈÄâÊã©Âô®: {selector}")
                                break
                        except:
                            continue
                    
                    if search_toggle:
                        # Ê£ÄÊü•ÊòØÂê¶Â∑≤ÁªèÊøÄÊ¥ª
                        is_active = False
                        
                        # ÊñπÊ°à A: Ê£ÄÊü• class ‰∏≠ÊòØÂê¶ÂåÖÂê´ÊøÄÊ¥ªÁä∂ÊÄÅ
                        try:
                            class_attr = search_toggle.get_attribute("class") or ""
                            parent_class = ""
                            try:
                                parent_class = page.evaluate("el => el.parentElement?.className || ''", search_toggle.element_handle())
                            except:
                                pass
                            
                            # Ê£ÄÊü•ÊòØÂê¶ÂåÖÂê´ÊøÄÊ¥ªÁõ∏ÂÖ≥ÁöÑÂÖ≥ÈîÆÂ≠ó
                            if any(keyword in (class_attr + parent_class).lower() for keyword in ["checked", "active", "on", "enabled", "selected"]):
                                is_active = True
                                self.logger.debug(f"ÈÄöËøá class Âà§Êñ≠ÔºöÂ∑≤ÊøÄÊ¥ª (class: {class_attr}, parent: {parent_class})")
                            
                            # ÊñπÊ°à B: Ê£ÄÊü•È¢úËâ≤ÊàñÊ†∑Âºè
                            if not is_active:
                                try:
                                    color = page.evaluate("el => window.getComputedStyle(el).color", search_toggle.element_handle())
                                    bg_color = page.evaluate("el => window.getComputedStyle(el).backgroundColor", search_toggle.element_handle())
                                    # DeepSeek ÊøÄÊ¥ªÊó∂ÈÄöÂ∏∏ÊòØËìùËâ≤ #247fff (rgb(36, 127, 255))
                                    if "rgb(36, 127, 255)" in color or "rgb(36, 127, 255)" in bg_color:
                                        is_active = True
                                        self.logger.debug(f"ÈÄöËøáÈ¢úËâ≤Âà§Êñ≠ÔºöÂ∑≤ÊøÄÊ¥ª (color: {color}, bg: {bg_color})")
                                    # Â¶ÇÊûúÈ¢úËâ≤‰∏çÊòØÈªòËÆ§ÁöÑÁÅ∞Ëâ≤/ÈªëËâ≤ÔºåÂèØËÉΩÂ∑≤ÊøÄÊ¥ª
                                    elif "rgb(0, 0, 0)" not in color and "rgb(128" not in color and color:
                                        # Ëøõ‰∏ÄÊ≠•Ê£ÄÊü•ÔºöÂ¶ÇÊûúÊñáÂ≠óÈ¢úËâ≤ÊòéÊòæ‰∏çÊòØÁÅ∞Ëâ≤ÔºåÂèØËÉΩÊòØÊøÄÊ¥ªÁä∂ÊÄÅ
                                        if "rgb(36" in color or "rgb(24" in color:  # ËìùËâ≤Á≥ª
                                            is_active = True
                                            self.logger.debug(f"ÈÄöËøáÈ¢úËâ≤Âà§Êñ≠ÔºàËìùËâ≤Á≥ªÔºâÔºöÂ∑≤ÊøÄÊ¥ª (color: {color})")
                                except Exception as color_error:
                                    self.logger.debug(f"Ê£ÄÊü•È¢úËâ≤Â§±Ë¥•: {color_error}")
                            
                            # ÊñπÊ°à C: Â¶ÇÊûúÊó†Ê≥ïÁ°ÆÂÆöÔºåÊ£ÄÊü•Áà∂Á∫ßÊàñÂêåÁ∫ßÂÖÉÁ¥†ÁöÑÊøÄÊ¥ªÁä∂ÊÄÅ
                            if not is_active:
                                try:
                                    # Êü•ÊâæÁà∂Á∫ßÂÆπÂô®ÔºåÊ£ÄÊü•ÊòØÂê¶ÊúâÊøÄÊ¥ªÊ†áËÆ∞
                                    parent_active = page.evaluate("""
                                        el => {
                                            let parent = el.closest('[class*="toggle"], [class*="switch"], [class*="button"]');
                                            if (!parent) return false;
                                            let className = parent.className || '';
                                            return /checked|active|on|enabled|selected/i.test(className);
                                        }
                                    """, search_toggle.element_handle())
                                    if parent_active:
                                        is_active = True
                                        self.logger.debug("ÈÄöËøáÁà∂Á∫ßÂÖÉÁ¥†Âà§Êñ≠ÔºöÂ∑≤ÊøÄÊ¥ª")
                                except:
                                    pass

                            if is_active:
                                self.logger.info("‚úÖ Ê£ÄÊµãÂà∞'ËÅîÁΩëÊêúÁ¥¢'Â∑≤ÈªòËÆ§ÂºÄÂêØÔºåË∑≥ËøáÁÇπÂáª„ÄÇ")
                            else:
                                # Â¶ÇÊûúÊó†Ê≥ïÁ°ÆÂÆöÁä∂ÊÄÅÔºåÊàñËÄÖÁ°ÆÂÆöÊú™ÊøÄÊ¥ªÔºåÂàôÁÇπÂáªÂºÄÂêØ
                                self.logger.info("üîÑ ËÅîÁΩëÊêúÁ¥¢Êú™ÂºÄÂêØÔºåÊ≠£Âú®ÁÇπÂáªÂºÄÂêØ...")
                                search_toggle.click()
                                time.sleep(0.8)  # Á≠âÂæÖÁä∂ÊÄÅÊõ¥Êñ∞
                                self.logger.info("‚úÖ Â∑≤ÊâãÂä®ÂºÄÂêØ'ËÅîÁΩëÊêúÁ¥¢'")
                        except Exception as check_error:
                            self.logger.warning(f"Âà§Êñ≠ÊêúÁ¥¢ÂºÄÂÖ≥Áä∂ÊÄÅÂ§±Ë¥•: {check_error}ÔºåÂ∞ÜÂº∫Âà∂ÁÇπÂáª‰ª•Á°Æ‰øùÂºÄÂêØ")
                            # Â¶ÇÊûúÂà§Êñ≠Â§±Ë¥•Ôºå‰∏∫‰∫ÜÁ°Æ‰øùÊåâÈíÆÂºÄÂêØÔºåÂº∫Âà∂ÁÇπÂáª
                            try:
                                search_toggle.click()
                                time.sleep(0.8)
                                self.logger.info("‚úÖ Â∑≤Âº∫Âà∂ÁÇπÂáªÂºÄÂêØ'ËÅîÁΩëÊêúÁ¥¢'ÔºàÂà§Êñ≠Â§±Ë¥•ÂêéÁöÑÂÆâÂÖ®Êé™ÊñΩÔºâ")
                            except:
                                pass
                    else:
                        # Â¶ÇÊûúÊâæ‰∏çÂà∞ÊåâÈíÆÔºåËÆ∞ÂΩïË≠¶ÂëäÔºå‰ΩÜ‰∏çÈòªÂ°ûÊµÅÁ®ã
                        self.logger.warning("‚ö†Ô∏è Êú™ÊâæÂà∞'ËÅîÁΩëÊêúÁ¥¢'ÊåâÈíÆÔºåÂèØËÉΩÈ°µÈù¢ÁªìÊûÑÂ∑≤ÂèòÊõ¥ÊàñÊåâÈíÆÂ∑≤ÈªòËÆ§ÂºÄÂêØ")
                except Exception as e:
                    self.logger.warning(f"Â§ÑÁêÜËÅîÁΩëÊêúÁ¥¢ÂºÄÂÖ≥Â§±Ë¥•: {e}ÔºåÁªßÁª≠ÊâßË°åÔºàÂèØËÉΩÊåâÈíÆÂ∑≤ÈªòËÆ§ÂºÄÂêØÔºâ")
                
                # 3. ÁÇπÂáªÂèëÈÄÅÊåâÈíÆ
                try:
                    # Ê†πÊçÆÊúÄÊñ∞ UIÔºåÂèëÈÄÅÊåâÈíÆÊòØ‰∏Ä‰∏™ËìùËâ≤ÁöÑÂúÜÂΩ¢ÂõæÊ†áÊåâÈíÆ
                    # Â∞ùËØïÂ§ö‰∏™ÂèØËÉΩÁöÑÈÄâÊã©Âô®
                    send_selectors = [
                        "div[class*='_7436f3']", # Â∏∏ËßÅÁöÑÁ±ªÂêçÊ®°Âºè
                        "button:has(svg)",       # ÂåÖÂê´ÂõæÊ†áÁöÑÊåâÈíÆ
                        ".ds-icon--send",        # ÂõæÊ†áÁ±ªÂêç
                        "div[role='button'] >> svg" # ËßíËâ≤‰∏∫ÊåâÈíÆÁöÑ div ‰∏ãÁöÑ svg
                    ]
                    
                    sent = False
                    for selector in send_selectors:
                        btn = page.locator(selector).last
                        if btn.is_visible() and btn.is_enabled():
                            btn.click()
                            sent = True
                            self.logger.info(f"ÈÄöËøáÈÄâÊã©Âô® {selector} ÁÇπÂáª‰∫ÜÂèëÈÄÅÊåâÈíÆ")
                            break
                    
                    if not sent:
                        # Â§áÈÄâÔºö‰ΩøÁî®ÈîÆÁõòÂø´Êç∑ÈîÆ
                        page.keyboard.press("Enter") # ÊàñËÄÖ Control+Enter
                        self.logger.info("Â∑≤ÈÄöËøá Enter ÈîÆÂèëÈÄÅ")
                        
                except Exception as e:
                    self.logger.warning(f"ÁÇπÂáªÂèëÈÄÅÊåâÈíÆÂ§±Ë¥•: {e}")
                    page.keyboard.press("Control+Enter")
                
                self.logger.info("Â∑≤ÂèëÈÄÅÊèêÈóÆÔºåÁ≠âÂæÖ AI ÂõûÁ≠î...")
                
                # 4. Á≠âÂæÖÂõûÁ≠îÁîüÊàêÂÆåÊàê
                time.sleep(5)  # Á≠âÂæÖËØ∑Ê±ÇÂèëÈÄÅ
                
                # Á≠âÂæÖÂõûÁ≠îÂÆπÂô®Âá∫Áé∞
                content_selector = ".ds-markdown"
                try:
                    page.wait_for_selector(content_selector, timeout=self.timeout)
                except:
                    self.logger.warning("Êú™ÂèëÁé∞ .ds-markdown ÂÆπÂô®")
                
                # Âæ™ÁéØÊ£ÄÊü•ÁîüÊàêÁä∂ÊÄÅ
                max_retries = 30
                max_retry_attempts = 3  # ÊúÄÂ§ßÈáçËØïÊ¨°Êï∞
                retry_count = 0  # ÂΩìÂâçÈáçËØïÊ¨°Êï∞
                last_content = ""
                
                for i in range(max_retries):
                    time.sleep(2)
                    try:
                        # Ê£ÄÊµãÊòØÂê¶Âá∫Áé∞Âà∑Êñ∞ÊåâÈíÆÔºàÂ§±Ë¥•Áä∂ÊÄÅÔºâ
                        refresh_button = None
                        # ‰ΩøÁî® JavaScript Êü•ÊâæÂà∑Êñ∞ÊåâÈíÆÔºåÊõ¥ÂèØÈù†
                        try:
                            refresh_button = page.evaluate_handle("""
                                () => {
                                    // Êü•ÊâæÊâÄÊúâÂèØËÉΩÁöÑÂà∑Êñ∞ÊåâÈíÆ
                                    const buttons = document.querySelectorAll('div.ds-icon-button, div[role="button"].ds-icon-button');
                                    
                                    for (const btn of buttons) {
                                        // Ê£ÄÊü•ÊòØÂê¶Âú®Ê∂àÊÅØÂÖÉÁ¥†‰∏≠
                                        const inMessage = btn.closest('div.ds-message');
                                        if (!inMessage) continue;
                                        
                                        // Ê£ÄÊü•ÊòØÂê¶ÂåÖÂê´ SVG
                                        const svg = btn.querySelector('svg');
                                        if (!svg) continue;
                                        
                                        // Ê£ÄÊü• SVG Ë∑ØÂæÑÊòØÂê¶ÂåÖÂê´Âà∑Êñ∞ÂõæÊ†áÁöÑÁâπÂæÅ
                                        const path = svg.querySelector('path');
                                        if (!path) continue;
                                        
                                        const pathData = path.getAttribute('d') || '';
                                        
                                        // Ê£ÄÊü•Ë∑ØÂæÑÊòØÂê¶ÂåÖÂê´Âà∑Êñ∞ÂõæÊ†áÁöÑÁâπÂæÅÔºàM1.27206 ÊàñÁ±ª‰ººÁöÑË∑ØÂæÑÔºâ
                                        // Âà∑Êñ∞ÂõæÊ†áÁöÑË∑ØÂæÑÈÄöÂ∏∏ÂæàÈïø‰∏îÂåÖÂê´ÁâπÂÆöÁöÑÊï∞ÂÄº
                                        if (pathData && (pathData.includes('M1.27206') || pathData.includes('1.27206') || pathData.length > 200)) {
                                            // Ëøõ‰∏ÄÊ≠•È™åËØÅÔºöÊ£ÄÊü•ÊòØÂê¶ÂèØËßÅ
                                            const style = window.getComputedStyle(btn);
                                            if (style.display !== 'none' && style.visibility !== 'hidden' && style.opacity !== '0') {
                                                return btn;
                                            }
                                        }
                                    }
                                    return null;
                                }
                            """)
                            
                            # Â¶ÇÊûúÊâæÂà∞‰∫ÜÊåâÈíÆÔºåÊ£ÄÊü•ÊòØÂê¶ÁúüÁöÑÂ≠òÂú®
                            if refresh_button and refresh_button.as_element():
                                # È™åËØÅÂÖÉÁ¥†ÊòØÂê¶‰ªçÁÑ∂ÂèØËßÅ
                                try:
                                    element = refresh_button.as_element()
                                    if element and element.is_visible():
                                        refresh_button = element
                                    else:
                                        refresh_button = None
                                except:
                                    refresh_button = None
                            else:
                                refresh_button = None
                        except Exception as e:
                            self.logger.debug(f"Ê£ÄÊµãÂà∑Êñ∞ÊåâÈíÆÊó∂Âá∫Èîô: {e}")
                            refresh_button = None
                        
                        # Â¶ÇÊûúÊ£ÄÊµãÂà∞Âà∑Êñ∞ÊåâÈíÆÔºåËØ¥ÊòéÂ§±Ë¥•‰∫ÜÔºåÈúÄË¶ÅÈáçËØï
                        if refresh_button:
                            retry_count += 1
                            self.logger.warning(f"‚ö†Ô∏è Ê£ÄÊµãÂà∞Â§±Ë¥•Áä∂ÊÄÅÔºàÂà∑Êñ∞ÊåâÈíÆÂá∫Áé∞ÔºâÔºåÂºÄÂßãÁ¨¨ {retry_count}/{max_retry_attempts} Ê¨°ÈáçËØï...")
                            
                            if retry_count > max_retry_attempts:
                                self.logger.error(f"‚ùå ÈáçËØïÊ¨°Êï∞Â∑≤Ëææ‰∏äÈôê ({max_retry_attempts} Ê¨°)ÔºåÂÅúÊ≠¢ÈáçËØï")
                                raise Exception(f"DeepSeek ÂõûÁ≠îÁîüÊàêÂ§±Ë¥•ÔºåÂ∑≤ÈáçËØï {max_retry_attempts} Ê¨°")
                            
                            # ÁÇπÂáªÂà∑Êñ∞ÊåâÈíÆ
                            try:
                                refresh_button.click()
                                self.logger.info(f"üîÑ Â∑≤ÁÇπÂáªÂà∑Êñ∞ÊåâÈíÆÔºåÁ≠âÂæÖÈáçÊñ∞ÁîüÊàê...")
                                time.sleep(3)  # Á≠âÂæÖÂà∑Êñ∞ÂêéÁöÑÂìçÂ∫î
                                
                                # ÈáçÁΩÆÁ≠âÂæÖÁä∂ÊÄÅ
                                last_content = ""
                                
                                # ÈáçÊñ∞Á≠âÂæÖÂõûÁ≠îÂÆπÂô®Âá∫Áé∞
                                try:
                                    page.wait_for_selector(content_selector, timeout=self.timeout)
                                except:
                                    self.logger.warning("ÈáçËØïÂêéÊú™ÂèëÁé∞ .ds-markdown ÂÆπÂô®ÔºåÁªßÁª≠Á≠âÂæÖ...")
                                
                                continue  # ÁªßÁª≠Âæ™ÁéØÔºåÁ≠âÂæÖÊñ∞ÁöÑÂõûÁ≠îÁîüÊàê
                            except Exception as click_error:
                                self.logger.error(f"‚ùå ÁÇπÂáªÂà∑Êñ∞ÊåâÈíÆÂ§±Ë¥•: {click_error}")
                                raise Exception(f"Êó†Ê≥ïÁÇπÂáªÂà∑Êñ∞ÊåâÈíÆËøõË°åÈáçËØï: {click_error}")
                        
                        # Â∞ùËØïËé∑ÂèñÂΩìÂâçÂÜÖÂÆπ
                        content_el = page.query_selector(content_selector)
                        if content_el:
                            current_content = content_el.inner_text()
                            
                            # Ê£ÄÊü•ÊòØÂê¶ÁîüÊàêÂÆåÊàê
                            if len(current_content) > 100:
                                if current_content == last_content:
                                    # ÂÜÖÂÆπ‰∏çÂÜçÂèòÂåñÔºåÊ£ÄÊü•ÊòØÂê¶Êúâ"ÂÅúÊ≠¢ÁîüÊàê"ÊåâÈíÆ
                                    stop_btn = page.query_selector("text=ÂÅúÊ≠¢ÁîüÊàê")
                                    if not stop_btn:
                                        if retry_count > 0:
                                            self.logger.info(f"‚úÖ ÂõûÁ≠îÁîüÊàêÂ∑≤ÂÆåÊàêÔºàÁªèËøá {retry_count} Ê¨°ÈáçËØïÔºâ")
                                        else:
                                            self.logger.info("ÂõûÁ≠îÁîüÊàêÂ∑≤ÂÆåÊàê")
                                        full_response_text = current_content
                                        break
                                
                            last_content = current_content
                            if retry_count > 0:
                                self.logger.info(f"Ê≠£Âú®ÁîüÊàê‰∏≠... (ÂΩìÂâçÈïøÂ∫¶: {len(current_content)}, Â∑≤ÊçïËé∑ {len(captured_search_results)} ‰∏™ÊêúÁ¥¢ÁªìÊûú, ÈáçËØïÊ¨°Êï∞: {retry_count})")
                            else:
                                self.logger.info(f"Ê≠£Âú®ÁîüÊàê‰∏≠... (ÂΩìÂâçÈïøÂ∫¶: {len(current_content)}, Â∑≤ÊçïËé∑ {len(captured_search_results)} ‰∏™ÊêúÁ¥¢ÁªìÊûú)")
                    except Exception as e:
                        # Â¶ÇÊûúÊòØÈáçËØïÊ¨°Êï∞Ë∂ÖÈôêÁöÑÂºÇÂ∏∏ÔºåÁõ¥Êé•ÊäõÂá∫
                        if "ÈáçËØïÊ¨°Êï∞Â∑≤Ëææ‰∏äÈôê" in str(e) or "Êó†Ê≥ïÁÇπÂáªÂà∑Êñ∞ÊåâÈíÆ" in str(e):
                            raise
                        continue
                
                # 5. Êï∞ÊçÆÂ∑≤‰ªéÁΩëÁªúÊé•Âè£ÊäìÂèñÂÆåÊàêÔºå‰ºòÂÖà‰ΩøÁî®Êé•Âè£Êï∞ÊçÆ
                if len(captured_search_results) == 0:
                    self.logger.warning("Êú™ÈÄöËøá API Êé•Âè£ÊäìÂèñÂà∞ÂºïÁî®ÔºåÂ∞ùËØï‰ªé DOM ÊèêÂèñ‰Ωú‰∏∫Ë°•ÂÖÖ...")
                    api_captured_urls = set()
                else:
                    self.logger.info(f"Â∑≤ÈÄöËøá API Êé•Âè£ÊäìÂèñÂà∞ {len(captured_search_results)} ‰∏™ÂºïÁî®")
                    api_captured_urls = {r.get('url', '') for r in captured_search_results if r.get('url')}
                
                # Â¶ÇÊûúÊé•Âè£Ê≤°ÊúâÊäìÂèñÂà∞Êï∞ÊçÆÔºåÂ∞ùËØï‰ªé DOM ÊèêÂèñ‰Ωú‰∏∫ÊúÄÂêéÊâãÊÆµ
                if len(captured_search_results) == 0:
                    try:
                        # Â∞ùËØïÂ§öÁßçÊñπÂºèÊèêÂèñÂºïÁî®ÈìæÊé•
                        # DeepSeek ‰ΩøÁî® ds-markdown-cite Á±ªÊ†áËÆ∞ÂºïÁî®
                        # ‰ºòÂÖàÊèêÂèñÂ∏¶ÂºïÁî®Ê†áËÆ∞ÁöÑÈìæÊé•
                        link_selectors = [
                            ".ds-markdown a[href^='http'] .ds-markdown-cite",  # ‰ºòÂÖàÔºöÂ∏¶ÂºïÁî®Ê†áËÆ∞ÁöÑÈìæÊé•
                            ".ds-markdown a[href^='https'] .ds-markdown-cite",
                            ".ds-markdown a[href^='http']",  # markdown ÂÜÖÂÆπ‰∏≠ÁöÑÊâÄÊúâÈìæÊé•
                            ".ds-markdown a[href^='https']",
                            "a[href^='http'] .ds-markdown-cite",  # ÊâÄÊúâÂ∏¶ÂºïÁî®Ê†áËÆ∞ÁöÑÈìæÊé•
                            "a[href^='https'] .ds-markdown-cite",
                            "a[href^='http']",  # ÊâÄÊúâÂ§ñÈÉ®ÈìæÊé•
                            "a[href^='https']",
                            "[class*='citation'] a",  # ÂºïÁî®Áõ∏ÂÖ≥ÁöÑÈìæÊé•
                            "[class*='reference'] a",
                            "[class*='source'] a",  # Êù•Ê∫êÁõ∏ÂÖ≥ÁöÑÈìæÊé•
                        ]
                        
                        seen_dom_urls = set(api_captured_urls)  # ‰ªé API Â∑≤ÊçïËé∑ÁöÑ URL ÂºÄÂßã
                        dom_extracted_count = 0
                        
                        for selector in link_selectors:
                            try:
                                links = page.query_selector_all(selector)
                                self.logger.debug(f"ÈÄâÊã©Âô® '{selector}' ÊâæÂà∞ {len(links)} ‰∏™ÈìæÊé•")
                                
                                for link in links:
                                    try:
                                        # Â¶ÇÊûúÈÄâÊã©Âô®ÂåπÈÖçÁöÑÊòØ .ds-markdown-citeÔºåÈúÄË¶ÅÊâæÂà∞Áà∂ÈìæÊé•
                                        link_tag = link.evaluate("el => el.tagName.toLowerCase()")
                                        link_class = link.get_attribute("class") or ""
                                        
                                        if link_tag == 'span' or 'ds-markdown-cite' in link_class:
                                            # ÊâæÂà∞Áà∂Á∫ß a Ê†áÁ≠æ
                                            try:
                                                parent_a = link.evaluate_handle("el => el.closest('a')")
                                                if parent_a:
                                                    link = parent_a
                                                else:
                                                    # Â¶ÇÊûúÊâæ‰∏çÂà∞Áà∂ aÔºåË∑≥ËøáËøô‰∏™ÂÖÉÁ¥†
                                                    continue
                                            except:
                                                continue
                                        
                                        href = link.get_attribute("href")
                                        if not href:
                                            continue
                                        
                                        # ËøáÊª§Êéâ DeepSeek Ëá™Â∑±ÁöÑÂüüÂêç
                                        if any(d in href.lower() for d in ["deepseek.com", "deepseek.ai"]):
                                            continue
                                        
                                        # ÂéªÈáç
                                        if href in seen_dom_urls:
                                            continue
                                        seen_dom_urls.add(href)
                                        
                                        # ÊèêÂèñÂºïÁî®Â∫èÂè∑ÔºàÂÖ≥ÈîÆ‰øÆÂ§çÔºö‰ªé ds-markdown-cite ‰∏≠ÊèêÂèñÔºâ
                                        cite_index = 0
                                        try:
                                            # Êü•ÊâæÈìæÊé•ÂÜÖÁöÑ ds-markdown-cite ÂÖÉÁ¥†
                                            cite_element = link.query_selector(".ds-markdown-cite")
                                            if cite_element:
                                                # ‰ªé cite ÂÖÉÁ¥†‰∏≠ÊèêÂèñÂ∫èÂè∑
                                                cite_text = cite_element.inner_text().strip()
                                                # Â∞ùËØï‰ªéÊñáÊú¨‰∏≠ÊèêÂèñÊï∞Â≠óÔºàÂ¶Ç "1", "2"Ôºâ
                                                import re
                                                match = re.search(r'\d+', cite_text)
                                                if match:
                                                    cite_index = int(match.group())
                                                else:
                                                    # Â∞ùËØï‰ªé span ÁöÑÁªùÂØπÂÆö‰ΩçÂÖÉÁ¥†‰∏≠ÊèêÂèñ
                                                    cite_number = cite_element.evaluate("""
                                                        el => {
                                                            let spans = el.querySelectorAll('span');
                                                            for (let span of spans) {
                                                                let text = span.textContent.trim();
                                                                let num = parseInt(text);
                                                                if (!isNaN(num) && num > 0) {
                                                                    return num;
                                                                }
                                                            }
                                                            return 0;
                                                        }
                                                    """)
                                                    cite_index = cite_number or 0
                                        except Exception as e:
                                            self.logger.debug(f"ÊèêÂèñÂºïÁî®Â∫èÂè∑Â§±Ë¥•: {e}")
                                        
                                        # Â¶ÇÊûúÊ≤°ÊúâÊâæÂà∞Â∫èÂè∑ÔºåÂ∞ùËØï‰ªéÈìæÊé•Âë®Âõ¥ÁöÑÊñáÊú¨‰∏≠ÊèêÂèñ
                                        if cite_index == 0:
                                            try:
                                                # Êü•ÊâæÈìæÊé•ÂâçÁöÑÂºïÁî®Ê†áËÆ∞
                                                prev_text = link.evaluate("""
                                                    el => {
                                                        let text = el.textContent || '';
                                                        let match = text.match(/\\[(\\d+)\\]/);
                                                        if (match) return parseInt(match[1]);
                                                        
                                                        // Êü•ÊâæÁà∂ÂÖÉÁ¥†‰∏≠ÁöÑÂºïÁî®Ê†áËÆ∞
                                                        let parent = el.parentElement;
                                                        if (parent) {
                                                            let parentText = parent.textContent || '';
                                                            let parentMatch = parentText.match(/\\[(\\d+)\\]/);
                                                            if (parentMatch) return parseInt(parentMatch[1]);
                                                        }
                                                        return 0;
                                                    }
                                                """)
                                                cite_index = prev_text or 0
                                            except:
                                                pass
                                        
                                        # Â¶ÇÊûúËøòÊòØÊ≤°ÊúâÊâæÂà∞Â∫èÂè∑Ôºå‰ΩøÁî®ÂΩìÂâçËÆ°Êï∞
                                        if cite_index == 0:
                                            cite_index = len(captured_search_results) + 1
                                        
                                        # ÊèêÂèñÊ†áÈ¢ò
                                        title = link.inner_text().strip()
                                        # ÁßªÈô§ÂºïÁî®Ê†áËÆ∞ÔºàÂ¶Ç [1]Ôºâ‰ªéÊ†áÈ¢ò‰∏≠
                                        import re
                                        title = re.sub(r'\[\d+\]', '', title).strip()
                                        
                                        if not title:
                                            # Â∞ùËØï‰ªéÁà∂ÂÖÉÁ¥†ÊàñÈôÑËøëÂÖÉÁ¥†Ëé∑Âèñ
                                            try:
                                                parent_text = link.evaluate("""
                                                    el => {
                                                        let parent = el.parentElement;
                                                        if (parent) {
                                                            let text = parent.textContent || '';
                                                            // ÁßªÈô§ÂºïÁî®Ê†áËÆ∞
                                                            text = text.replace(/\\[\\d+\\]/g, '').trim();
                                                            return text.substring(0, 100);
                                                        }
                                                        return '';
                                                    }
                                                """)
                                                title = parent_text
                                            except:
                                                pass
                                        
                                        # ÊèêÂèñÊëòË¶ÅÔºàÂ∞ùËØï‰ªéÈôÑËøëÂÖÉÁ¥†Ôºâ
                                        snippet = ""
                                        try:
                                            sibling_text = link.evaluate("""
                                                el => {
                                                    let next = el.nextElementSibling;
                                                    if (next && next.textContent) {
                                                        return next.textContent.trim().substring(0, 200);
                                                    }
                                                    let parent = el.parentElement;
                                                    if (parent && parent.nextElementSibling) {
                                                        return parent.nextElementSibling.textContent.trim().substring(0, 200);
                                                    }
                                                    return '';
                                                }
                                            """)
                                            snippet = sibling_text
                                        except:
                                            pass
                                        
                                        captured_search_results.append({
                                            "url": href,
                                            "title": title or extract_domain(href),
                                            "snippet": snippet,
                                            "site_name": extract_domain(href),
                                            "cite_index": cite_index
                                        })
                                        dom_extracted_count += 1
                                        self.logger.debug(f"‰ªé DOM ÊçïËé∑ÂºïÁî®: {href[:50]}... (cite_index: {cite_index})")
                                    except Exception as e:
                                        self.logger.debug(f"ÊèêÂèñÈìæÊé•Â§±Ë¥•: {e}")
                                        continue
                            except Exception as e:
                                self.logger.debug(f"ÈÄâÊã©Âô® '{selector}' ÊâßË°åÂ§±Ë¥•: {e}")
                                continue
                    
                        self.logger.info(f"‰ªé DOM ÊèêÂèñÂà∞ {dom_extracted_count} ‰∏™Êñ∞ÂºïÁî®ÈìæÊé•ÔºàAPI Â∑≤ÊçïËé∑ {len(api_captured_urls)} ‰∏™Ôºâ")
                        
                        # Â∞ùËØïÊü•ÊâæÂºïÁî®ÂàóË°®Âå∫ÂüüÔºàDeepSeek ÂèØËÉΩÂú®Â∫ïÈÉ®Êàñ‰æßËæπÊòæÁ§∫ÂºïÁî®ÂàóË°®Ôºâ
                        try:
                            # Êü•ÊâæÂèØËÉΩÁöÑÂºïÁî®ÂàóË°®ÂÆπÂô®
                            citation_containers = [
                                "[class*='citation']",
                                "[class*='reference']",
                                "[class*='source']",
                                "[class*='link-list']",
                                "[class*='reference-list']"
                            ]
                            
                            for container_selector in citation_containers:
                                try:
                                    containers = page.query_selector_all(container_selector)
                                    if containers:
                                        self.logger.debug(f"ÊâæÂà∞ {len(containers)} ‰∏™ÂèØËÉΩÁöÑÂºïÁî®ÂÆπÂô®: {container_selector}")
                                        for container in containers:
                                            # Âú®ÂÆπÂô®ÂÜÖÊü•ÊâæÈìæÊé•
                                            container_links = container.query_selector_all("a[href^='http']")
                                            for link in container_links:
                                                try:
                                                    href = link.get_attribute("href")
                                                    if href and href not in seen_dom_urls:
                                                        seen_dom_urls.add(href)
                                                        title = link.inner_text().strip() or extract_domain(href)
                                                        captured_search_results.append({
                                                            "url": href,
                                                            "title": title,
                                                            "snippet": "",
                                                            "site_name": extract_domain(href),
                                                            "cite_index": len(captured_search_results) + 1
                                                        })
                                                        dom_extracted_count += 1
                                                except:
                                                    continue
                                except:
                                    continue
                        except Exception as e:
                            self.logger.debug(f"Êü•ÊâæÂºïÁî®ÂàóË°®ÂÆπÂô®Â§±Ë¥•: {e}")
                    except Exception as e:
                        self.logger.warning(f"‰ªé DOM ÊèêÂèñÂºïÁî®Â§±Ë¥•: {e}")
                
                # 6. Êï¥ÁêÜÊêúÁ¥¢ÁªìÊûúÔºàÂéªÈáçÔºâ
                seen_urls = set()
                unique_citations = []
                for result in captured_search_results:
                    url = result.get('url', '')
                    if url and url not in seen_urls:
                        seen_urls.add(url)
                        unique_citations.append({
                            "url": url,
                            "title": result.get('title', ''),
                            "snippet": result.get('snippet', ''),
                            "site_name": result.get('site_name', ''),
                            "cite_index": result.get('cite_index', 0)
                        })
                
                # Êåâ cite_index ÊéíÂ∫è
                unique_citations.sort(key=lambda x: x.get('cite_index', 999))
                
                # ËÆ°ÁÆóÊï∞ÊçÆÊù•Ê∫êÁªüËÆ°
                api_captured_count = len(api_captured_urls)
                dom_extracted_count = len(unique_citations) - api_captured_count
                if dom_extracted_count < 0:
                    dom_extracted_count = 0
                
                # Êï∞ÊçÆÊçïËé∑Ê±áÊÄªÊó•Âøó
                self.logger.info("")
                self.logger.info("=" * 60)
                self.logger.info("üìä Êï∞ÊçÆÊçïËé∑Ê±áÊÄª")
                self.logger.info("=" * 60)
                
                # Êü•ËØ¢‰ø°ÊÅØÊ±áÊÄª
                self.logger.info(f"üîç Êü•ËØ¢‰ø°ÊÅØ (ÂÖ± {len(captured_queries)} ‰∏™):")
                if captured_queries:
                    for idx, q in enumerate(captured_queries, 1):
                        self.logger.info(f"  {idx}. \"{q}\"")
                else:
                    self.logger.info("  (Êú™ÊçïËé∑Âà∞Êü•ËØ¢)")
                
                # ÁΩëÁ´ô‰ø°ÊÅØÊ±áÊÄª
                self.logger.info("")
                self.logger.info(f"üåê ÊäìÂèñÁΩëÁ´ô (ÂÖ± {len(unique_citations)} ‰∏™ÂîØ‰∏ÄÁΩëÁ´ô):")
                self.logger.info(f"  - API Êã¶Êà™: {api_captured_count} ‰∏™")
                self.logger.info(f"  - DOM ÊèêÂèñ: {dom_extracted_count} ‰∏™")
                
                if unique_citations:
                    # ÊåâÂüüÂêçÂàÜÁªÑÁªüËÆ°
                    domain_count = {}
                    for cite in unique_citations:
                        domain = cite.get('site_name', 'unknown')
                        domain_count[domain] = domain_count.get(domain, 0) + 1
                    
                    self.logger.info("")
                    self.logger.info("  ÁΩëÁ´ôÂàóË°® (Ââç15‰∏™):")
                    for cite in unique_citations[:15]:
                        cite_index = cite.get('cite_index', 0)
                        site_name = cite.get('site_name', 'unknown')
                        title = cite.get('title', '')[:40] or '(Êó†Ê†áÈ¢ò)'
                        url = cite.get('url', '')[:50]
                        self.logger.info(f"    [{cite_index}] {site_name}: {title}... ({url}...)")
                    
                    if len(unique_citations) > 15:
                        self.logger.info(f"    ... ËøòÊúâ {len(unique_citations) - 15} ‰∏™ÁΩëÁ´ôÊú™ÊòæÁ§∫")
                    
                    self.logger.info("")
                    self.logger.info("  ÂüüÂêçÂàÜÂ∏É (Ââç10‰∏™):")
                    sorted_domains = sorted(domain_count.items(), key=lambda x: x[1], reverse=True)
                    for domain, count in sorted_domains[:10]:
                        self.logger.info(f"    {domain}: {count} Ê¨°")
                else:
                    self.logger.info("  (Êú™ÊçïËé∑Âà∞ÁΩëÁ´ô)")
                
                self.logger.info("")
                self.logger.info("=" * 60)
                self.logger.info("‚úÖ Êï∞ÊçÆÊçïËé∑ÂÆåÊàê")
                self.logger.info(f"   - Êü•ËØ¢: {len(captured_queries)} ‰∏™")
                self.logger.info(f"   - ÁΩëÁ´ô: {len(unique_citations)} ‰∏™")
                self.logger.info("=" * 60)
                self.logger.info("")
                
                # Â¶ÇÊûúÊçïËé∑Êï∞ÈáèÊòéÊòæÂ∞ë‰∫éÈ¢ÑÊúüÔºåËæìÂá∫Ë∞ÉËØï‰ø°ÊÅØ
                if len(unique_citations) < 3:
                    self.logger.warning("‚ö†Ô∏è ÊçïËé∑Âà∞ÁöÑÂºïÁî®Êï∞ÈáèËæÉÂ∞ëÔºåÂèØËÉΩÂ≠òÂú®ÈóÆÈ¢ò")
                    self.logger.info("üí° Ë∞ÉËØïÂª∫ËÆÆÔºö")
                    self.logger.info("   1. Ê£ÄÊü•È°µÈù¢‰∏≠ÊòØÂê¶Á°ÆÂÆûÊòæÁ§∫‰∫ÜÂºïÁî®ÈìæÊé•")
                    self.logger.info("   2. Êü•ÁúãÊµèËßàÂô®ÂºÄÂèëËÄÖÂ∑•ÂÖ∑ÁöÑ Network Ê†áÁ≠æÔºåÊâæÂà∞ API ÂìçÂ∫î")
                    self.logger.info("   3. Ê£ÄÊü•È°µÈù¢ HTML ‰∏≠ÂºïÁî®ÈìæÊé•ÁöÑÂÆûÈôÖÁªìÊûÑ")
                
                return {
                    "full_text": full_response_text or last_content,
                    "queries": captured_queries,  # ÊãìÂ±ïËØç
                    "citations": unique_citations  # ÂèÇËÄÉÁΩëÈ°µ
                }
            finally:
                browser.close()
