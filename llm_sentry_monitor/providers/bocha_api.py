import os
import json
import time
import requests
from typing import Dict, Any, List
from providers.base import BaseProvider
from core.parser import extract_domain


class BochaApiProvider(BaseProvider):
    """
    åšæŸ¥ (Bocha AI) API Provider
    ä½¿ç”¨ Bocha AI Web Search API è¿›è¡Œæœç´¢
    API æ–‡æ¡£: https://bocha-ai.feishu.cn/wiki/HmtOw1z6vik14Fkdu5uc9VaInBb
    API ç«¯ç‚¹: https://api.bocha.cn/v1/web-search
    """
    
    def __init__(self, headless: bool = False, timeout: int = 30000):
        super().__init__(headless=headless, timeout=timeout)
        self.api_key = os.getenv("BOCHA_API_KEY")
        self.api_base_url = os.getenv("BOCHA_API_BASE_URL", "https://api.bocha.cn")
        
        if not self.api_key:
            self.logger.warning("BOCHA_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œæœç´¢åŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
    
    def search(self, keyword: str, prompt: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨åšæŸ¥ API è¿›è¡Œæœç´¢
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            prompt: æç¤ºè¯ï¼ˆé€šå¸¸ä¸ keyword ç›¸åŒï¼‰
        
        Returns:
            åŒ…å« full_text, queries, citations çš„å­—å…¸
        """
        if not self.api_key:
            raise ValueError("BOCHA_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œæ— æ³•ä½¿ç”¨åšæŸ¥ API")
        
        self.logger.info(f"ğŸ” å¼€å§‹ä½¿ç”¨åšæŸ¥ API æœç´¢: {keyword}")
        
        try:
            # æ„å»º API è¯·æ±‚
            # API æ–‡æ¡£: https://bocha-ai.feishu.cn/wiki/HmtOw1z6vik14Fkdu5uc9VaInBb
            api_url = f"{self.api_base_url}/v1/web-search"
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            # æ„å»ºè¯·æ±‚ payload
            payload = {
                "query": prompt or keyword,
                "summary": True,
                "freshness": "noLimit",
                "count": 10
            }
            
            self.logger.info(f"ğŸ“¡ å‘é€è¯·æ±‚åˆ°: {api_url}")
            self.logger.debug(f"è¯·æ±‚å‚æ•°: {json.dumps(payload, ensure_ascii=False)}")
            
            # å‘é€ HTTP è¯·æ±‚
            response = requests.post(
                api_url,
                headers=headers,
                json=payload,
                timeout=self.timeout / 1000  # è½¬æ¢ä¸ºç§’
            )
            
            response.raise_for_status()
            data = response.json()
            
            self.logger.info(f"âœ… æ”¶åˆ°åšæŸ¥ API å“åº”")
            self.logger.debug(f"å“åº”æ•°æ®ç»“æ„: {list(data.keys()) if isinstance(data, dict) else 'éå­—å…¸ç±»å‹'}")
            
            # è§£æå“åº”æ•°æ®
            # æ ¹æ®å®é™…çš„ API å“åº”æ ¼å¼è°ƒæ•´è§£æé€»è¾‘
            full_text = ""
            queries = []
            citations = []
            
            # æå–å›ç­”æ–‡æœ¬ï¼ˆæ‘˜è¦ï¼‰
            # æ ¹æ®åšæŸ¥ API æ–‡æ¡£ï¼Œå“åº”å¯èƒ½åŒ…å« summary å­—æ®µ
            if "summary" in data:
                summary_data = data.get("summary")
                if isinstance(summary_data, str):
                    full_text = summary_data
                elif isinstance(summary_data, dict):
                    full_text = summary_data.get("text", summary_data.get("content", summary_data.get("summary", "")))
            elif "answer" in data:
                full_text = data.get("answer", "")
            elif "content" in data:
                full_text = data.get("content", "")
            elif "text" in data:
                full_text = data.get("text", "")
            elif "response" in data:
                response_data = data.get("response", {})
                if isinstance(response_data, str):
                    full_text = response_data
                elif isinstance(response_data, dict):
                    full_text = response_data.get("text", response_data.get("content", ""))
            
            # æå–æŸ¥è¯¢è¯ï¼ˆæ‹“å±•è¯ï¼‰
            if "queries" in data:
                queries = data.get("queries", [])
                if isinstance(queries, str):
                    queries = [queries]
            elif "search_queries" in data:
                queries = data.get("search_queries", [])
                if isinstance(queries, str):
                    queries = [queries]
            
            # æå–å¼•ç”¨ï¼ˆæœç´¢ç»“æœï¼‰
            # æ ¹æ®åšæŸ¥ API æ–‡æ¡£ï¼Œå“åº”å¯èƒ½åŒ…å« results æˆ– items å­—æ®µ
            if "results" in data:
                results = data.get("results", [])
                for idx, result in enumerate(results):
                    if isinstance(result, dict):
                        url = result.get("url", result.get("link", result.get("href", "")))
                        if url:
                            citations.append({
                                "url": url,
                                "title": result.get("title", result.get("name", "")),
                                "snippet": result.get("snippet", result.get("description", result.get("summary", ""))),
                                "site_name": result.get("site_name", result.get("source", extract_domain(url))),
                                "cite_index": result.get("cite_index", result.get("index", idx + 1)),
                                "query_indexes": result.get("query_indexes", [])
                            })
            elif "items" in data:
                items = data.get("items", [])
                for idx, item in enumerate(items):
                    if isinstance(item, dict):
                        url = item.get("url", item.get("link", item.get("href", "")))
                        if url:
                            citations.append({
                                "url": url,
                                "title": item.get("title", item.get("name", "")),
                                "snippet": item.get("snippet", item.get("description", item.get("summary", ""))),
                                "site_name": item.get("site_name", item.get("source", extract_domain(url))),
                                "cite_index": item.get("cite_index", item.get("index", idx + 1)),
                                "query_indexes": item.get("query_indexes", [])
                            })
            elif "citations" in data and isinstance(data.get("citations"), list):
                citations_data = data.get("citations", [])
                for idx, cite in enumerate(citations_data):
                    if isinstance(cite, dict):
                        url = cite.get("url", cite.get("link", cite.get("href", "")))
                        if url:
                            citations.append({
                                "url": url,
                                "title": cite.get("title", cite.get("name", "")),
                                "snippet": cite.get("snippet", cite.get("description", cite.get("summary", ""))),
                                "site_name": cite.get("site_name", cite.get("source", extract_domain(url))),
                                "cite_index": cite.get("cite_index", cite.get("index", idx + 1)),
                                "query_indexes": cite.get("query_indexes", [])
                            })
            elif "references" in data:
                references = data.get("references", [])
                for idx, ref in enumerate(references):
                    if isinstance(ref, dict):
                        url = ref.get("url", ref.get("link", ref.get("href", "")))
                        if url:
                            citations.append({
                                "url": url,
                                "title": ref.get("title", ref.get("name", "")),
                                "snippet": ref.get("snippet", ref.get("description", ref.get("summary", ""))),
                                "site_name": ref.get("site_name", ref.get("source", extract_domain(url))),
                                "cite_index": ref.get("cite_index", ref.get("index", idx + 1)),
                                "query_indexes": ref.get("query_indexes", [])
                            })
            
            # å¦‚æœæ²¡æœ‰æå–åˆ°æŸ¥è¯¢è¯ï¼Œä½¿ç”¨åŸå§‹å…³é”®è¯
            if not queries:
                queries = [keyword] if keyword else []
            
            # æ—¥å¿—è¾“å‡º
            self.logger.info(f"\n{'='*60}")
            self.logger.info(f"ğŸ“Š åšæŸ¥ API æ•°æ®æ•è·æ±‡æ€»")
            self.logger.info(f"{'='*60}")
            self.logger.info(f"ğŸ” æŸ¥è¯¢ä¿¡æ¯ (å…± {len(queries)} ä¸ª):")
            for idx, q in enumerate(queries, 1):
                self.logger.info(f"  {idx}. \"{q}\"")
            
            self.logger.info(f"\nğŸŒ æŠ“å–ç½‘ç«™ (å…± {len(citations)} ä¸ª):")
            for cite in citations[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                self.logger.info(f"  [{cite.get('cite_index', 0)}] {cite.get('site_name', 'unknown')}: {cite.get('title', '')[:50]}...")
            
            if len(citations) > 10:
                self.logger.info(f"  ... è¿˜æœ‰ {len(citations) - 10} ä¸ªç½‘ç«™æœªæ˜¾ç¤º")
            
            self.logger.info(f"\nğŸ“ å›ç­”æ–‡æœ¬é•¿åº¦: {len(full_text)} å­—ç¬¦")
            if full_text:
                self.logger.info(f"   æ–‡æœ¬é¢„è§ˆ: {full_text[:100]}...")
            
            self.logger.info(f"{'='*60}\n")
            
            return {
                "full_text": full_text,
                "queries": queries,
                "citations": citations
            }
            
        except requests.exceptions.RequestException as e:
            error_msg = f"åšæŸ¥ API è¯·æ±‚å¤±è´¥: {str(e)}"
            self.logger.error(error_msg, exc_info=True)
            raise Exception(error_msg)
        except json.JSONDecodeError as e:
            error_msg = f"åšæŸ¥ API å“åº”è§£æå¤±è´¥: {str(e)}"
            self.logger.error(error_msg, exc_info=True)
            raise Exception(error_msg)
        except Exception as e:
            error_msg = f"åšæŸ¥ API æœç´¢å¤±è´¥: {str(e)}"
            self.logger.error(error_msg, exc_info=True)
            raise Exception(error_msg)
