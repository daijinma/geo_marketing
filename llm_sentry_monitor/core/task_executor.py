"""
core/task_executor.py - ä»»åŠ¡æ‰§è¡Œå™¨
å°è£…ä»»åŠ¡æ‰§è¡Œé€»è¾‘ï¼Œæ”¯æŒå¤šå…³é”®è¯ã€å¤šå¹³å°çš„å¼‚æ­¥æ‰§è¡Œ
"""
import os
import time
import logging
import threading
from typing import List, Dict, Any, Optional
from core.db import get_db_connection, update_domain_stats
from core.parser import extract_domain
from providers.deepseek_web import DeepSeekWebProvider
from providers.doubao_web import DoubaoWebProvider

logger = logging.getLogger(__name__)


def save_to_db(keyword, platform, prompt, result, prompt_type="default", response_time_ms=None, error_message=None):
    """ä¿å­˜æœç´¢ç»“æœåˆ°æ•°æ®åº“ï¼ˆä» main.py å¤ç”¨ï¼‰"""
    try:
        with get_db_connection() as conn:
            cur = conn.cursor()
            
            # ç¡®å®šæœç´¢çŠ¶æ€
            search_status = 'completed' if result and result.get("full_text") else 'failed'
            if error_message:
                search_status = 'failed'
            
            # 1. æ’å…¥æœç´¢è®°å½•
            cur.execute("""
                INSERT INTO search_records 
                (keyword, platform, prompt_type, prompt, full_answer, response_time_ms, search_status, error_message) 
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s) 
                RETURNING id
            """, (
                keyword, 
                platform, 
                prompt_type, 
                prompt,
                result.get("full_text", "") if result else "",
                response_time_ms,
                search_status,
                error_message
            ))
            record_id = cur.fetchone()[0]
            
            if not result:
                logger.warning(f"æœç´¢å¤±è´¥ï¼Œä»…ä¿å­˜äº†è®°å½• ID: {record_id}")
                return record_id, 0
            
            # 2. æ’å…¥æ‹“å±•è¯ (å¸¦é¡ºåº)
            for idx, query in enumerate(result.get("queries", []), 1):
                cur.execute(
                    "INSERT INTO search_queries (record_id, query, query_order) VALUES (%s, %s, %s)",
                    (record_id, query, idx)
                )
            
            # 3. æ’å…¥å¼•ç”¨ (åˆ©ç”¨å”¯ä¸€çº¦æŸè‡ªåŠ¨å»é‡)
            citations_count = 0
            for cite in result.get("citations", []):
                url = cite.get("url", "")
                if not url:
                    continue
                    
                domain = extract_domain(url)
                try:
                    cur.execute("""
                        INSERT INTO citations 
                        (record_id, cite_index, url, domain, title, snippet, site_name) 
                        VALUES (%s, %s, %s, %s, %s, %s, %s)
                        ON CONFLICT (record_id, url) DO NOTHING
                    """, (
                        record_id, 
                        cite.get("cite_index", 0), 
                        url, 
                        domain, 
                        cite.get("title", ""), 
                        cite.get("snippet", ""), 
                        cite.get("site_name", "")
                    ))
                    
                    if cur.rowcount > 0:
                        citations_count += 1
                        # æ›´æ–°åŸŸåç»Ÿè®¡
                        update_domain_stats(conn, domain, platform)
                        
                except Exception as e:
                    logger.debug(f"æ’å…¥å¼•ç”¨å¤±è´¥ï¼ˆå¯èƒ½é‡å¤ï¼‰: {e}")
            
            logger.info(f"âœ… æˆåŠŸä¿å­˜ {platform} çš„æ•°æ®ï¼Œè®°å½• ID: {record_id}")
            logger.info(f"  - æ‹“å±•è¯: {len(result.get('queries', []))} ä¸ª")
            logger.info(f"  - å‚è€ƒç½‘é¡µ: {citations_count} ä¸ª")
            if response_time_ms:
                logger.info(f"  - å“åº”æ—¶é—´: {response_time_ms/1000:.2f} ç§’")
            
            return record_id, citations_count
                
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}", exc_info=True)
        return None, 0


def execute_single_task(keyword: str, platform: str, prompt: str, settings: Dict[str, Any]) -> Dict[str, Any]:
    """
    æ‰§è¡Œå•ä¸ªå…³é”®è¯-å¹³å°ç»„åˆçš„æœç´¢ä»»åŠ¡
    
    Args:
        keyword: æœç´¢å…³é”®è¯
        platform: å¹³å°åç§° (deepseek, doubao)
        prompt: æç¤ºè¯
        settings: è®¾ç½®å­—å…¸ (headless, timeoutç­‰)
    
    Returns:
        åŒ…å«æ‰§è¡Œç»“æœçš„å­—å…¸
    """
    headless = settings.get("headless", False)
    timeout = settings.get("timeout", 60000)
    
    providers = {
        "deepseek": DeepSeekWebProvider(headless=headless, timeout=timeout),
        "doubao": DoubaoWebProvider(headless=headless, timeout=timeout)
    }
    
    # å¹³å°åç§°è§„èŒƒåŒ–
    platform_lower = platform.lower().strip()
    matched_platform = None
    for key in providers.keys():
        if key.lower() == platform_lower:
            matched_platform = key
            break
    
    if not matched_platform:
        return {
            "keyword": keyword,
            "platform": platform,
            "status": "failed",
            "error_message": f"æœªæ‰¾åˆ°å¹³å° [{platform}] çš„ Provider",
            "record_id": None,
            "citations_count": 0
        }
    
    provider = providers[matched_platform]
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡: [{keyword}] åœ¨å¹³å° [{matched_platform}]")
    logger.info(f"{'='*60}")
    
    start_time = time.time()
    result = None
    error_message = None
    
    try:
        result = provider.search(keyword, prompt)
        response_time_ms = int((time.time() - start_time) * 1000)
        
        if result and result.get("full_text"):
            record_id, citations_count = save_to_db(
                keyword, matched_platform, prompt, result, 
                prompt_type="api_task", 
                response_time_ms=response_time_ms
            )
            logger.info(f"âœ… {matched_platform} ä»»åŠ¡å®Œæˆ")
            return {
                "keyword": keyword,
                "platform": matched_platform,
                "status": "completed",
                "record_id": record_id,
                "citations_count": citations_count,
                "response_time_ms": response_time_ms
            }
        else:
            error_message = "æœªè¿”å›æœ‰æ•ˆç»“æœ"
            logger.warning(f"âš ï¸ {matched_platform} {error_message}")
            record_id, _ = save_to_db(
                keyword, matched_platform, prompt, None, 
                prompt_type="api_task", 
                error_message=error_message
            )
            return {
                "keyword": keyword,
                "platform": matched_platform,
                "status": "failed",
                "error_message": error_message,
                "record_id": record_id,
                "citations_count": 0
            }
            
    except Exception as e:
        response_time_ms = int((time.time() - start_time) * 1000)
        error_message = str(e)
        logger.error(f"âŒ æ‰§è¡Œä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        record_id, _ = save_to_db(
            keyword, matched_platform, prompt, None, 
            prompt_type="api_task", 
            response_time_ms=response_time_ms, 
            error_message=error_message
        )
        return {
            "keyword": keyword,
            "platform": matched_platform,
            "status": "failed",
            "error_message": error_message,
            "record_id": record_id,
            "citations_count": 0,
            "response_time_ms": response_time_ms
        }


def execute_task_job(task_id: int, keywords: List[str], platforms: List[str], settings: Dict[str, Any]):
    """
    åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œä»»åŠ¡ä½œä¸š
    
    Args:
        task_id: ä»»åŠ¡ID
        keywords: å…³é”®è¯åˆ—è¡¨
        platforms: å¹³å°åˆ—è¡¨
        settings: è®¾ç½®å­—å…¸
    """
    def run():
        try:
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸º pending
            with get_db_connection() as conn:
                cur = conn.cursor()
                cur.execute(
                    "UPDATE task_jobs SET status = 'pending' WHERE id = %s",
                    (task_id,)
                )
                conn.commit()
            
            results = []
            delay = settings.get("delay_between_tasks", 5)
            
            # æ‰§è¡Œæ‰€æœ‰å…³é”®è¯-å¹³å°ç»„åˆ
            for keyword in keywords:
                prompt = keyword  # ä½¿ç”¨å…³é”®è¯ä½œä¸ºæç¤ºè¯
                for platform in platforms:
                    result = execute_single_task(keyword, platform, prompt, settings)
                    results.append(result)
                    
                    # ä»»åŠ¡é—´å»¶è¿Ÿ
                    if delay > 0:
                        time.sleep(delay)
            
            # æ›´æ–°ä»»åŠ¡ç»“æœ
            import json
            with get_db_connection() as conn:
                cur = conn.cursor()
                cur.execute("""
                    UPDATE task_jobs 
                    SET status = 'done', result_data = %s 
                    WHERE id = %s
                """, (json.dumps(results), task_id))
                conn.commit()
            
            logger.info(f"âœ… ä»»åŠ¡ {task_id} æ‰§è¡Œå®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ ä»»åŠ¡ {task_id} æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸º doneï¼Œä½†è®°å½•é”™è¯¯
            try:
                import json
                with get_db_connection() as conn:
                    cur = conn.cursor()
                    error_result = [{"error": str(e)}]
                    cur.execute("""
                        UPDATE task_jobs 
                        SET status = 'done', result_data = %s 
                        WHERE id = %s
                    """, (json.dumps(error_result), task_id))
                    conn.commit()
            except:
                pass
    
    # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œ
    thread = threading.Thread(target=run, daemon=True)
    thread.start()

