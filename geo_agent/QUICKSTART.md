# geo_agent å¿«é€Ÿå¼€å§‹æŒ‡å—

## 5 åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹

### 0. å®‰è£… uvï¼ˆé¦–æ¬¡ä½¿ç”¨ï¼‰

```bash
# macOS / Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# éªŒè¯å®‰è£…
uv --version
```

> **ä¸ºä»€ä¹ˆä½¿ç”¨ uv?**  
> uv æ˜¯ Rust ç¼–å†™çš„ç°ä»£ Python åŒ…ç®¡ç†å™¨ï¼Œæ¯” pip å¿« 10-100 å€ï¼Œè‡ªåŠ¨ç®¡ç†è™šæ‹Ÿç¯å¢ƒã€‚

### 1. å®‰è£…ä¾èµ–

```bash
cd geo_agent
make install
# æˆ–
uv sync
```

### 2. é…ç½® API Key

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
# å¤åˆ¶ç¤ºä¾‹æ–‡ä»¶
cp .env.example .env

# ç¼–è¾‘ .envï¼Œæ·»åŠ ä½ çš„ API Key
# DASHSCOPE_API_KEY=sk-your-key-here
```

è·å– DashScope API Keyï¼š
1. è®¿é—® https://dashscope.console.aliyun.com/
2. ç™»å½•é˜¿é‡Œäº‘è´¦å·
3. åˆ›å»º API Key

### 3. å¯åŠ¨æœåŠ¡

```bash
make dev
```

çœ‹åˆ°ä»¥ä¸‹è¾“å‡ºè¡¨ç¤ºå¯åŠ¨æˆåŠŸï¼š

```
INFO:     Uvicorn running on http://0.0.0.0:8100 (Press CTRL+C to quit)
```

### 4. æµ‹è¯•æœåŠ¡

#### æ–¹æ³• 1: ä½¿ç”¨ curl

```bash
curl http://localhost:8100/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen3-max",
    "messages": [{"role": "user", "content": "ä½ å¥½"}]
  }'
```

#### æ–¹æ³• 2: ä½¿ç”¨ Python

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8100/v1",
    api_key="test"
)

response = client.chat.completions.create(
    model="qwen3-max",
    messages=[{"role": "user", "content": "ä½ å¥½"}]
)

print(response.choices[0].message.content)
```

#### æ–¹æ³• 3: ä½¿ç”¨æµ‹è¯•è„šæœ¬

```bash
python test_agent.py
```

### 5. æŸ¥çœ‹æ—¥å¿—

```bash
# å®æ—¶æŸ¥çœ‹ Qwen API è°ƒç”¨æ—¥å¿—
make logs-qwen

# æŸ¥çœ‹æ‰€æœ‰æ—¥å¿—
make logs
```

## é›†æˆåˆ°ä½ çš„é¡¹ç›®

### JavaScript/TypeScript

```typescript
import OpenAI from 'openai';

const client = new OpenAI({
  baseURL: 'http://localhost:8100/v1',
  apiKey: 'dummy'
});

const response = await client.chat.completions.create({
  model: 'qwen3-max',
  messages: [{ role: 'user', content: 'Hello' }]
});

console.log(response.choices[0].message.content);
```

### Python

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8100/v1",
    api_key="dummy"
)

response = client.chat.completions.create(
    model="qwen3-max",
    messages=[{"role": "user", "content": "Hello"}]
)

print(response.choices[0].message.content)
```

### Go

```go
package main

import (
    "context"
    "fmt"
    openai "github.com/sashabaranov/go-openai"
)

func main() {
    config := openai.DefaultConfig("dummy")
    config.BaseURL = "http://localhost:8100/v1"
    client := openai.NewClientWithConfig(config)

    resp, err := client.CreateChatCompletion(
        context.Background(),
        openai.ChatCompletionRequest{
            Model: "qwen3-max",
            Messages: []openai.ChatCompletionMessage{
                {Role: "user", Content: "Hello"},
            },
        },
    )

    if err != nil {
        panic(err)
    }

    fmt.Println(resp.Choices[0].Message.Content)
}
```

## å¸¸è§ç”¨ä¾‹

### 1. ç®€å•é—®ç­”

```python
response = client.chat.completions.create(
    model="qwen3-max",
    messages=[
        {"role": "user", "content": "Python æ˜¯ä»€ä¹ˆï¼Ÿ"}
    ]
)
```

### 2. å¸¦ç³»ç»Ÿæç¤ºè¯

```python
response = client.chat.completions.create(
    model="qwen3-max",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ª Python ä¸“å®¶"},
        {"role": "user", "content": "è§£é‡Šè£…é¥°å™¨"}
    ]
)
```

### 3. å¤šè½®å¯¹è¯

```python
messages = [
    {"role": "user", "content": "æˆ‘å«å°æ˜"},
    {"role": "assistant", "content": "ä½ å¥½å°æ˜ï¼"},
    {"role": "user", "content": "æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ"}
]

response = client.chat.completions.create(
    model="qwen3-max",
    messages=messages
)
```

### 4. æµå¼å“åº”

```python
stream = client.chat.completions.create(
    model="qwen3-max",
    messages=[{"role": "user", "content": "å†™ä¸€é¦–è¯—"}],
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

### 5. è°ƒæ•´å‚æ•°

```python
response = client.chat.completions.create(
    model="qwen3-max",
    messages=[{"role": "user", "content": "ç”Ÿæˆä¸€ä¸ªæ•…äº‹"}],
    temperature=0.9,      # æ›´éšæœº
    max_tokens=500,       # é™åˆ¶é•¿åº¦
    top_p=0.95
)
```

## ç›‘æ§å’Œè°ƒè¯•

### æŸ¥çœ‹å®æ—¶æ—¥å¿—

```bash
# ç»ˆç«¯ 1: å¯åŠ¨æœåŠ¡
make dev

# ç»ˆç«¯ 2: æŸ¥çœ‹æ—¥å¿—
make logs-qwen
```

### ç»Ÿè®¡ä¿¡æ¯

```bash
make stats
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
Token usage statistics:
Total API calls: 42
Total tokens used: 12500
Average latency (ms): 1234.56
```

## æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: è¿æ¥è¢«æ‹’ç»

**æ£€æŸ¥**: æœåŠ¡æ˜¯å¦å¯åŠ¨ï¼Ÿ

```bash
curl http://localhost:8100/health
```

### é—®é¢˜ 2: API Key é”™è¯¯

**æ£€æŸ¥**: `.env` æ–‡ä»¶æ˜¯å¦é…ç½®æ­£ç¡®ï¼Ÿ

```bash
cat .env | grep DASHSCOPE_API_KEY
```

### é—®é¢˜ 3: å“åº”æ…¢

**æ£€æŸ¥**: æŸ¥çœ‹æ—¥å¿—ä¸­çš„ `latency_ms`

```bash
make logs-qwen
```

## ä¸‹ä¸€æ­¥

- ğŸ“– é˜…è¯»å®Œæ•´æ–‡æ¡£: [README.md](README.md)
- ğŸ§ª è¿è¡Œæµ‹è¯•å¥—ä»¶: `python test_agent.py`
- ğŸ“Š æŸ¥çœ‹ API æ–‡æ¡£: http://localhost:8100/docs
- ğŸ“ æŸ¥çœ‹æ—¥å¿—: `make logs`

## éœ€è¦å¸®åŠ©ï¼Ÿ

æŸ¥çœ‹å®Œæ•´æ–‡æ¡£æˆ–æ£€æŸ¥æ—¥å¿—æ–‡ä»¶è·å–æ›´å¤šä¿¡æ¯ã€‚
