"""
Test script for geo_agent service

This script tests the OpenAI-compatible API endpoints
"""
from openai import OpenAI
import time
import sys

def test_basic_chat(client):
    """Test basic chat completion"""
    print("\n" + "="*50)
    print("æµ‹è¯• 1: åŸºæœ¬èŠå¤©è¡¥å…¨")
    print("="*50)
    
    try:
        start = time.time()
        response = client.chat.completions.create(
            model="qwen3-max",
            messages=[
                {"role": "user", "content": "1+1ç­‰äºå‡ ï¼Ÿè¯·ç®€çŸ­å›ç­”"}
            ]
        )
        latency = (time.time() - start) * 1000
        
        print(f"âœ… æˆåŠŸ")
        print(f"å›ç­”: {response.choices[0].message.content}")
        print(f"Tokens: {response.usage.total_tokens} (prompt: {response.usage.prompt_tokens}, completion: {response.usage.completion_tokens})")
        print(f"å»¶è¿Ÿ: {latency:.2f}ms")
        return True
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        return False

def test_system_prompt(client):
    """Test with system prompt"""
    print("\n" + "="*50)
    print("æµ‹è¯• 2: ç³»ç»Ÿæç¤ºè¯")
    print("="*50)
    
    try:
        start = time.time()
        response = client.chat.completions.create(
            model="qwen3-max",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ•°å­¦è€å¸ˆï¼Œå›ç­”è¦ç®€æ´æ¸…æ™°"},
                {"role": "user", "content": "ä»€ä¹ˆæ˜¯è´¨æ•°ï¼Ÿ"}
            ],
            temperature=0.7
        )
        latency = (time.time() - start) * 1000
        
        print(f"âœ… æˆåŠŸ")
        print(f"å›ç­”: {response.choices[0].message.content[:200]}...")
        print(f"Tokens: {response.usage.total_tokens}")
        print(f"å»¶è¿Ÿ: {latency:.2f}ms")
        return True
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        return False

def test_streaming(client):
    """Test streaming response"""
    print("\n" + "="*50)
    print("æµ‹è¯• 3: æµå¼å“åº”")
    print("="*50)
    
    try:
        start = time.time()
        stream = client.chat.completions.create(
            model="qwen3-max",
            messages=[
                {"role": "user", "content": "ä»1æ•°åˆ°5ï¼Œæ¯ä¸ªæ•°å­—ä¸€è¡Œ"}
            ],
            stream=True
        )
        
        print("æµå¼è¾“å‡º:")
        content = ""
        for chunk in stream:
            if chunk.choices[0].delta.content:
                content += chunk.choices[0].delta.content
                print(chunk.choices[0].delta.content, end="", flush=True)
        
        latency = (time.time() - start) * 1000
        print(f"\nâœ… æˆåŠŸ")
        print(f"æ€»é•¿åº¦: {len(content)} å­—ç¬¦")
        print(f"å»¶è¿Ÿ: {latency:.2f}ms")
        return True
    except Exception as e:
        print(f"\nâŒ å¤±è´¥: {e}")
        return False

def test_multi_turn(client):
    """Test multi-turn conversation"""
    print("\n" + "="*50)
    print("æµ‹è¯• 4: å¤šè½®å¯¹è¯")
    print("="*50)
    
    try:
        start = time.time()
        response = client.chat.completions.create(
            model="qwen3-max",
            messages=[
                {"role": "user", "content": "æˆ‘çš„åå­—æ˜¯å°æ˜"},
                {"role": "assistant", "content": "ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚"},
                {"role": "user", "content": "æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ"}
            ]
        )
        latency = (time.time() - start) * 1000
        
        print(f"âœ… æˆåŠŸ")
        print(f"å›ç­”: {response.choices[0].message.content}")
        print(f"å»¶è¿Ÿ: {latency:.2f}ms")
        
        # Check if the model remembers the name
        if "å°æ˜" in response.choices[0].message.content:
            print("âœ… ä¸Šä¸‹æ–‡ç†è§£æ­£ç¡®")
        else:
            print("âš ï¸  ä¸Šä¸‹æ–‡ç†è§£å¯èƒ½æœ‰é—®é¢˜")
        
        return True
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        return False

def test_parameters(client):
    """Test different parameters"""
    print("\n" + "="*50)
    print("æµ‹è¯• 5: å‚æ•°é…ç½®")
    print("="*50)
    
    try:
        # Test with low temperature
        start = time.time()
        response = client.chat.completions.create(
            model="qwen3-max",
            messages=[
                {"role": "user", "content": "è¯´ä¸€ä¸ªæ•°å­—"}
            ],
            temperature=0.1,
            max_tokens=10
        )
        latency = (time.time() - start) * 1000
        
        print(f"âœ… æˆåŠŸ")
        print(f"å›ç­” (temperature=0.1): {response.choices[0].message.content}")
        print(f"Tokens: {response.usage.total_tokens}")
        print(f"å»¶è¿Ÿ: {latency:.2f}ms")
        return True
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        return False

def test_models_endpoint(client):
    """Test /v1/models endpoint"""
    print("\n" + "="*50)
    print("æµ‹è¯• 6: æ¨¡å‹åˆ—è¡¨æ¥å£")
    print("="*50)
    
    try:
        models = client.models.list()
        print(f"âœ… æˆåŠŸ")
        print(f"å¯ç”¨æ¨¡å‹:")
        for model in models.data:
            print(f"  - {model.id} (owned by: {model.owned_by})")
        return True
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        return False

def main():
    """Run all tests"""
    print("="*50)
    print("geo_agent API æµ‹è¯•å¥—ä»¶")
    print("="*50)
    print("æœåŠ¡åœ°å€: http://localhost:8100")
    print()
    
    # Initialize client
    client = OpenAI(
        base_url="http://localhost:8100/v1",
        api_key="test"  # Dummy API key
    )
    
    # Run tests
    tests = [
        ("åŸºæœ¬èŠå¤©", test_basic_chat),
        ("ç³»ç»Ÿæç¤ºè¯", test_system_prompt),
        ("æµå¼å“åº”", test_streaming),
        ("å¤šè½®å¯¹è¯", test_multi_turn),
        ("å‚æ•°é…ç½®", test_parameters),
        ("æ¨¡å‹åˆ—è¡¨", test_models_endpoint),
    ]
    
    results = []
    for name, test_func in tests:
        try:
            result = test_func(client)
            results.append((name, result))
        except Exception as e:
            print(f"\nâŒ æµ‹è¯•å¼‚å¸¸: {e}")
            results.append((name, False))
        
        # Wait a bit between tests
        time.sleep(1)
    
    # Summary
    print("\n" + "="*50)
    print("æµ‹è¯•æ‘˜è¦")
    print("="*50)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{name}: {status}")
    
    print(f"\næ€»è®¡: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        return 0
    else:
        print(f"\nâš ï¸  {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")
        return 1

if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\næµ‹è¯•è¢«ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\n\næµ‹è¯•å¼‚å¸¸: {e}")
        sys.exit(1)
